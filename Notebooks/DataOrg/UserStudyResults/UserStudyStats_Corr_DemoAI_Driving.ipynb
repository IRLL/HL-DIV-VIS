{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy.stats import kurtosis, skew\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scikit_posthocs as sp\n",
    "from scipy.stats import wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempTopDir = '/Volumes/Britt_SSD/ReDoEvals3/UserStudy/'\n",
    "filePath = os.path.join(tempTopDir, 'GP_Main.parquet')\n",
    "\n",
    "filePath = os.path.join(tempTopDir, 'likertSlim.parquet')\n",
    "likertSlim = pd.read_parquet(filePath)\n",
    "\n",
    "\n",
    "likertSlim['visuals'] = np.where(likertSlim['visuals']==\"Visuals\",\"Charts\",\n",
    "                        np.where(likertSlim['visuals']==\"Blur_Plus_Vis\",\"Blur+Charts\",likertSlim['visuals']))\n",
    "\n",
    "# likertSlim['ag_correctedPerc'] = likertSlim['1_2_correctedPerc']\n",
    "# likertSlim['Q17_Z'] = likertSlim['17.0_Z']\n",
    "# likertSlim['Q18_Z'] = likertSlim['18.0_Z']\n",
    "# likertSlim['Q19_Z'] = likertSlim['19.0_Z']\n",
    "# likertSlim['Q20_Z'] = likertSlim['20.0_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n",
      "219\n"
     ]
    }
   ],
   "source": [
    "# drop particpants who have not been accepted (rejected or timed out)\n",
    "pID_removed1 = likertSlim[(likertSlim['status']!='APPROVED')].ParticipantPublicID.unique()\n",
    "print(len(likertSlim))\n",
    "# drop these given row\n",
    "# indexes from dataFrame\n",
    "likertSlim = likertSlim[~likertSlim['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "print(len(likertSlim))\n",
    "# tmp_slimDF = slimDF[~slimDF['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "# print(tmp_slimDF.status.unique())\n",
    "# print(pID_removed1)\n",
    "    \n",
    "# tmp_demoDF_L = demoDF_L[~demoDF_L['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "# tmp_demoDF_S = demoDF_S[~demoDF_S['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "\n",
    "# tmp_consentDF_L = consentDF_L[~consentDF_L['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "# tmp_consentDF_S = consentDF_S[~consentDF_S['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "\n",
    "# tmp_aiDF_L = aiDF_L[~aiDF_L['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "# tmp_aiDF_S = aiDF_S[~aiDF_S['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "\n",
    "# tmp_taskDF = taskDF[~taskDF['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "\n",
    "# print(tmp_taskDF[tmp_taskDF['ParticipantPublicID']==pID_removed1[-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blur+Charts 59\n",
      "Charts 51\n",
      "Blurred 53\n",
      "Video 56\n"
     ]
    }
   ],
   "source": [
    "df = likertSlim.copy()\n",
    "\n",
    "for vis in df.visuals.unique():\n",
    "    print(str(vis) + \" \" + str(len(df[df['visuals']==vis])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blur+Charts', 'Blurred', 'Charts', 'Video']\n"
     ]
    }
   ],
   "source": [
    "vis = sorted(df['visuals'].unique())\n",
    "print(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to make statsmodel into dataframe\n",
    "def results_summary_to_dataframe(results):\n",
    "    '''take the result of an statsmodel results table and transforms it into a dataframe'''\n",
    "    print(dir(results))\n",
    "    pvals = results.pvalues\n",
    "    coeff = results.params\n",
    "    conf_lower = results.conf_int()[0]\n",
    "    conf_higher = results.conf_int()[1]\n",
    "\n",
    "    results_df = pd.DataFrame({\"pvals\":pvals,\n",
    "                               \"coeff\":coeff,\n",
    "                               \"conf_lower\":conf_lower,\n",
    "                               \"conf_higher\":conf_higher\n",
    "                                })\n",
    "\n",
    "    #Reordering...\n",
    "    results_df = results_df[[\"coeff\",\"pvals\",\"conf_lower\",\"conf_higher\"]]\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ParticipantPrivateID', 'difficulty', 'visuals', 'agents', 'QsTotal', 'QsCorrect', 'Agent_QsTotal', 'Agent_QsCorrect', 'Agent_QsWO_GhostsTotal', 'Agent_QsWO_GhostsCorrect', 'Qs1_Correct', 'Qs2_Correct', 'QsPart_Total', 'predictionsCorrect', 'predictionsTotal', 'predictions1Correct', 'predictions2Correct', 'predictionsHalfTotal', 'regionsCorrect', 'regionsTotal', 'regions1Correct', 'regions2Correct', 'regionsHalfTotal', 'levelCorrect', 'levelTotal', 'level1Correct', 'level2Correct', 'levelHalfTotal', 'ghostsCorrect', 'ghostsTotal', 'ghosts1Correct', 'ghosts2Correct', 'ghostsHalfTotal', 'comparisonsCorrect', 'comparisonsTotal', 'timeTakenMain_All', 'timeTakenMain_AgentsOnly', 'timeTaken_Consent', 'timeTaken_Demographics', 'timeTaken_AI', 'timeTaken_Agent1', 'timeTaken_Agent2', 'timeTaken_Agent3', 'time_TOTAL', 'vidPlayed', 'avgVidPlays', 'ratioVidPlaysToAvg', 'ExperimentVersion_x', 'totPerc', 'agTotPerc', 'tot1Perc', 'tot2Perc', 'Agent_QsWO_GhostsPerc', 'predPerc', 'pred1Perc', 'pred2Perc', 'regPerc', 'reg1Perc', 'reg2Perc', 'lvlPerc', 'lvl1Perc', 'lvl2Perc', 'ghostPerc', 'ghost1Perc', 'ghost2Perc', 'compPerc', 'TreeNodeKey_x', 'age_info', 'age_info_text', 'age_info_quantised', 'gender_id', 'gender_id_text', 'gender_id_quantised', 'education_level', 'education_level_text', 'education_level_quantised', 'ExperimentVersion', 'ParticipantPublicID', 'ai_involvement_1', 'ai_involvement_2', 'ai_involvement_3', 'ai_involvement_4', 'ai_involvement_5', 'ai_involvement_6', 'ai_involvement_text', 'ai_involvement_other', 'ai_opinion', 'ai_opinion_quantised', 'AI_longForm', 'pacman_experience', 'pacman_experience_text', 'pacman_experience_quantised', 'ProlificName', 'status', 'age', 'num_approvals', 'num_rejections', 'prolific_score', 'Country of Birth', 'Current Country of Residence', 'Employment Status', 'First Language', 'Fluent languages', 'Gender identity', 'Nationality', 'Sex', 'Student Status', 'Suspicious', 'AmtPaid', 'Notes', 'Quality Rating(1-10)', 'Part1', 'Part2', 'Part3', 'MediaAI', 'HomeAI', 'AtWorkAI', 'ClassOnAI', 'DevelopAI', 'NoneAI', 'OtherAI', 'Car_Original_Response', 'Car_Explainable_Response', 'Car_Original_Rating', 'Car_Explainable_Rating', 'AIrating', 'blurring_helpful_1', 'blurring_helpful_2', 'charts_helpful_1', 'charts_helpful_2', 'info_sufficient_1', 'info_sufficient_2', 'irrelevant_distracting_1', 'irrelevant_distracting_2', 'scenarios_helpful_1', 'scenarios_helpful_2', 'likertMode', 'likert1Mode', 'likert2Mode', '17.0_Z', '18.0_Z', '19.0_Z', '20.0_Z', 'blurring_helpful_1_Z', 'blurring_helpful_2_Z', 'info_sufficient_1_Z', 'info_sufficient_2_Z', 'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z', 'irrelevant_distracting_1_Z', 'irrelevant_distracting_2_Z', 'charts_helpful_1_Z', 'charts_helpful_2_Z', 'Q17_Response', 'Q17_Correct', 'Q18_Response', 'Q18_Correct', 'Q19_Response', 'Q19_Correct', 'Q20_Response', 'Q20_Correct', 'CompCorrectSum', 'CompResponseMode', 'likertMode_Z', 'likert1Mode_Z', 'likert2Mode_Z', 'CompResponseMode_Z', 'likertMode_All_Z', 'compPerc_Z', 'agTotPerc_Z']\n"
     ]
    }
   ],
   "source": [
    "print(likertSlim.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_bold(val):\n",
    "    bold = 'bold' if val < 0 else ''\n",
    "    return 'font-weight: %s' % bold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "# Part Three\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "######################################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Note that the three terms returned are XÂ² statistic, p-value, and degree of freedom\n",
    "def testChiCorr(a,b,c):\n",
    "    ct = pd.crosstab(c[a], c[b], margins=True)\n",
    "    ar = []\n",
    "    for i in range(0, len(ct)-1):\n",
    "        ar.append(list(ct.iloc[i][0:-1].values))\n",
    "    obs = np.array(ar)\n",
    "    X, p, degF = stats.chi2_contingency(obs)[0:3]\n",
    "    if (p<0.05):\n",
    "        print(\"\\n\")\n",
    "        print(str(a) + \" \" + str(stats.tmean(c[a])) + \" \" + str(stats.tstd(c[a])))\n",
    "        print(str(b) + \" \" + str(stats.tmean(c[b])) + \" \" + str(stats.tstd(c[b])))\n",
    "#     else:\n",
    "#         print(\"\\n\"+ str(a) + \" \" + str(b))\n",
    "    return(X, p, degF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More explainable cars\n",
      "\n",
      "\n",
      "Car_Original_Rating 3.34703196347032 1.2146384873438487\n",
      "Car_Explainable_Rating 4.054794520547945 0.7937325184188475\n",
      "(70.27558302944387, 8.928919633159756e-09, 16)\n",
      "\n",
      "AI and liking sd Cars\n",
      "(20.39168274299768, 0.20309511648548678, 16)\n",
      "\n",
      "AI and preferring explainable Cars\n",
      "\n",
      "\n",
      "Car_Explainable_Rating 4.054794520547945 0.7937325184188475\n",
      "ai_opinion_quantised 3.6027397260273974 0.8790068315595534\n",
      "(42.635966819656645, 0.00031697401440959226, 16)\n",
      "\n",
      "Age and sd Cars\n",
      "(25.597282296377195, 0.3739099528959618, 24)\n",
      "\n",
      "Age and preferring explainable Cars\n",
      "(21.14402161181426, 0.6302150264186277, 24)\n",
      "\n",
      "Age and preferring explainable Cars\n",
      "(21.14402161181426, 0.6302150264186277, 24)\n",
      "[ 2.  1. nan  3.]\n",
      "[2. 1. 0. 3.]\n",
      "\n",
      "Gender and sd Cars\n",
      "\n",
      "\n",
      "Car_Original_Rating 3.34703196347032 1.2146384873438487\n",
      "gender_id_quantised 1.5068493150684932 0.5278471336058865\n",
      "(23.112632639424742, 0.026784803952831653, 12)\n",
      "\n",
      "Gender and preferring explainable Cars\n",
      "(5.51855597910644, 0.9383843696917461, 12)\n"
     ]
    }
   ],
   "source": [
    "# Part Three:\n",
    "\n",
    "# ORDINAL\n",
    "df = likertSlim.copy()\n",
    "# df = likertSlim[likertSlim['difficulty']==\"Easy\"].copy()\n",
    "# df = likertSlim[likertSlim['difficulty']==\"Difficult\"].copy()\n",
    "\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'Car_Original_Rating'\n",
    "b = 'Car_Explainable_Rating'\n",
    "print(\"More explainable cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'Car_Original_Rating'\n",
    "b = 'ai_opinion_quantised'\n",
    "print(\"\\nAI and liking sd Cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'Car_Explainable_Rating'\n",
    "b = 'ai_opinion_quantised'\n",
    "print(\"\\nAI and preferring explainable Cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'Car_Original_Rating'\n",
    "b = 'age_info_quantised'\n",
    "print(\"\\nAge and sd Cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "\n",
    "\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'Car_Explainable_Rating'\n",
    "b = 'age_info_quantised'\n",
    "print(\"\\nAge and preferring explainable Cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'Car_Explainable_Rating'\n",
    "b = 'age_info_quantised'\n",
    "print(\"\\nAge and preferring explainable Cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "\n",
    "#gender_id_quantised\n",
    "print(df['gender_id_quantised'].unique())\n",
    "df['gender_id_quantised'] = df['gender_id_quantised'].fillna(value=0)\n",
    "print(df['gender_id_quantised'].unique())\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'Car_Original_Rating'\n",
    "b = 'gender_id_quantised'\n",
    "print(\"\\nGender and sd Cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'Car_Explainable_Rating'\n",
    "b = 'gender_id_quantised'\n",
    "print(\"\\nGender and preferring explainable Cars\")\n",
    "print(testChiCorr(a,b,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More explainable cars\n",
      "(47.50039127901292, 0.7834555211407273, 56)\n",
      "\n",
      "AI and liking sd Cars\n",
      "(50.554557329341414, 0.680346348134365, 56)\n",
      "\n",
      "AI and preferring explainable Cars\n",
      "(71.40785913407781, 0.08043794856114488, 56)\n",
      "\n",
      "Age and sd Cars\n",
      "(63.67395193619157, 0.9519074171827786, 84)\n",
      "[ 2.  1. nan  3.]\n",
      "[2. 1. 0. 3.]\n",
      "\n",
      "Gender and sd Cars\n",
      "(38.45144545245882, 0.6275269171629065, 42)\n"
     ]
    }
   ],
   "source": [
    "# Part Three:\n",
    "\n",
    "# ORDINAL\n",
    "df = likertSlim.copy()\n",
    "# df = likertSlim[likertSlim['difficulty']==\"Easy\"].copy()\n",
    "# df = likertSlim[likertSlim['difficulty']==\"Difficult\"].copy()\n",
    "\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'Car_Original_Rating'\n",
    "b = 'totPerc'\n",
    "print(\"More explainable cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'totPerc'\n",
    "b = 'ai_opinion_quantised'\n",
    "print(\"\\nAI and liking sd Cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'Car_Explainable_Rating'\n",
    "b = 'totPerc'\n",
    "print(\"\\nAI and preferring explainable Cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'totPerc'\n",
    "b = 'age_info_quantised'\n",
    "print(\"\\nAge and sd Cars\")\n",
    "print(testChiCorr(a,b,df))\n",
    "\n",
    "\n",
    "\n",
    "#gender_id_quantised\n",
    "print(df['gender_id_quantised'].unique())\n",
    "df['gender_id_quantised'] = df['gender_id_quantised'].fillna(value=0)\n",
    "print(df['gender_id_quantised'].unique())\n",
    "# Chi-Square on likert1Mode v tot1Perc\n",
    "a = 'totPerc'\n",
    "b = 'gender_id_quantised'\n",
    "print(\"\\nGender and sd Cars\")\n",
    "print(testChiCorr(a,b,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: \n",
      "                               OLS Regression Results                              \n",
      "==================================================================================\n",
      "Dep. Variable:     Car_Explainable_Rating   R-squared:                       0.268\n",
      "Model:                                OLS   Adj. R-squared:                  0.265\n",
      "Method:                     Least Squares   F-statistic:                     79.51\n",
      "Date:                    Mon, 05 Jul 2021   Prob (F-statistic):           2.01e-16\n",
      "Time:                            12:59:29   Log-Likelihood:                -225.47\n",
      "No. Observations:                     219   AIC:                             454.9\n",
      "Df Residuals:                         217   BIC:                             461.7\n",
      "Df Model:                               1                                         \n",
      "Covariance Type:                nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept               2.9222      0.135     21.632      0.000       2.656       3.188\n",
      "Car_Original_Rating     0.3384      0.038      8.917      0.000       0.264       0.413\n",
      "==============================================================================\n",
      "Omnibus:                       18.132   Durbin-Watson:                   2.237\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               21.307\n",
      "Skew:                          -0.629   Prob(JB):                     2.36e-05\n",
      "Kurtosis:                       3.868   Cond. No.                         11.2\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Part Three:\n",
    "\n",
    "#'Car_Original_Response', 'Car_Explainable_Response'\n",
    "\n",
    "# Logistic\n",
    "pVal = 0.01\n",
    "rAdj = 0.05\n",
    "\n",
    "df = likertSlim.copy()\n",
    "# df = likertSlim[likertSlim['difficulty']==\"Easy\"].copy()\n",
    "# df = likertSlim[likertSlim['difficulty']==\"Difficult\"].copy()\n",
    "df['Car_Original_Response']=pd.Categorical(df['Car_Original_Response'])\n",
    "\n",
    "# Logistic Regression on likert1Mode v tot1Perc\n",
    "f_rev1 = 'tot1Perc ~ C(Car_Original_Response)'\n",
    "est = smf.ols(formula=f_rev1, data=df).fit()\n",
    "if est.f_pvalue < 0.05 and est.rsquared_adj > rAdj:\n",
    "    print('Summary: \\n', est.summary())\n",
    "\n",
    "# Logistic Regression on likert1Mode v tot2Perc\n",
    "f_rev1 = 'tot1Perc ~ C(Car_Explainable_Response)'\n",
    "est = smf.ols(formula=f_rev1, data=df).fit()\n",
    "if est.f_pvalue < 0.05 and est.rsquared_adj > rAdj:\n",
    "    print('Summary: \\n', est.summary())\n",
    "\n",
    "# Logistic Regression on likert1Mode v tot2Perc\n",
    "f_rev1 = 'Car_Explainable_Rating ~ Car_Original_Rating'\n",
    "est = smf.ols(formula=f_rev1, data=df).fit()\n",
    "if est.f_pvalue < 0.05 and est.rsquared_adj > rAdj:\n",
    "    print('Summary: \\n', est.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
