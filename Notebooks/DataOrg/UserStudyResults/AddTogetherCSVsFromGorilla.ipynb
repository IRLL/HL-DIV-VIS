{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import os, os.path\n",
    "import random\n",
    "import matrixprofile as mp\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import statistics\n",
    "from collections import Counter\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topFolder = '/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirs:\n",
      "['Short', 'Long']\n",
      "subdir\n",
      "/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/Demographics(yyjv)/\n",
      "dirs:\n",
      "[]\n",
      "subdir\n",
      "/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/Demographics(yyjv)/Long\n",
      "data_exp_31837-v60_questionnaire-yyjv.csv\n",
      "data_exp_31837-v62_questionnaire-yyjv.csv\n",
      "data_exp_31837-v64_questionnaire-yyjv.csv\n",
      "data_exp_31837-v65_questionnaire-yyjv.csv\n",
      "data_exp_31837-v67_questionnaire-yyjv copy.csv\n",
      "data_exp_31837-v67_questionnaire-yyjv.csv\n",
      "data_exp_31837-v70_questionnaire-yyjv.csv\n",
      "data_exp_31837-v72_questionnaire-yyjv.csv\n",
      "data_exp_31837-v73_questionnaire-yyjv.csv\n",
      "data_exp_31837-v76_questionnaire-yyjv copy.csv\n",
      "data_exp_31837-v76_questionnaire-yyjv.csv\n",
      "data_exp_31837-v77_questionnaire-yyjv.csv\n",
      "dirs:\n",
      "[]\n",
      "subdir\n",
      "/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/Demographics(yyjv)/Short\n",
      "data_exp_31837-v60_questionnaire-yyjv.csv\n",
      "data_exp_31837-v62_questionnaire-yyjv.csv\n",
      "data_exp_31837-v64_questionnaire-yyjv.csv\n",
      "data_exp_31837-v65_questionnaire-yyjv.csv\n",
      "data_exp_31837-v67_questionnaire-yyjv copy.csv\n",
      "data_exp_31837-v67_questionnaire-yyjv.csv\n",
      "data_exp_31837-v70_questionnaire-yyjv.csv\n",
      "data_exp_31837-v72_questionnaire-yyjv.csv\n",
      "data_exp_31837-v73_questionnaire-yyjv.csv\n",
      "data_exp_31837-v76_questionnaire-yyjv copy.csv\n",
      "data_exp_31837-v76_questionnaire-yyjv.csv\n",
      "data_exp_31837-v77_questionnaire-yyjv.csv\n",
      "246\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "demoPath = os.path.join(topFolder, 'Demographics(yyjv)/')\n",
    "demoDF_short = pd.DataFrame()\n",
    "demoDF_long = pd.DataFrame()\n",
    "\n",
    "for subdir, dirs, files in sorted(os.walk(demoPath)):\n",
    "    dir_name = os.path.basename(os.path.normpath(subdir))\n",
    "    print(\"dirs:\")\n",
    "    print(dirs)\n",
    "    print(\"subdir\")\n",
    "    print(subdir)\n",
    "\n",
    "    if dir_name == \"Long\":\n",
    "        for filename in sorted(files):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                print(filename)\n",
    "                path = os.path.join(subdir,filename)\n",
    "                tmp = pd.read_csv(path)\n",
    "                demoDF_long = pd.concat([demoDF_long,tmp],ignore_index=True)\n",
    "    if dir_name == \"Short\":\n",
    "        for filename in sorted(files):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                print(filename)\n",
    "                path = os.path.join(subdir,filename)\n",
    "                tmp = pd.read_csv(path)\n",
    "                demoDF_short = pd.concat([demoDF_short,tmp],ignore_index=True)\n",
    "                \n",
    "demoDF_short.columns = demoDF_short.columns.str.replace(' ', '')\n",
    "demoDF_short.columns = demoDF_short.columns.str.replace('-', '_')\n",
    "\n",
    "demoDF_long.columns = demoDF_long.columns.str.replace(' ', '')\n",
    "demoDF_long.columns = demoDF_long.columns.str.replace('-', '_')\n",
    "\n",
    "print(len(demoDF_short.ParticipantPrivateID.unique()))\n",
    "print(len(demoDF_long.ParticipantPrivateID.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirs:\n",
      "['Short', 'Long']\n",
      "subdir\n",
      "/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/AI_Intro(sh14)/\n",
      "dirs:\n",
      "[]\n",
      "subdir\n",
      "/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/AI_Intro(sh14)/Long\n",
      "data_exp_31837-v60_questionnaire-sh14.csv\n",
      "data_exp_31837-v62_questionnaire-sh14.csv\n",
      "data_exp_31837-v64_questionnaire-sh14.csv\n",
      "data_exp_31837-v65_questionnaire-sh14.csv\n",
      "data_exp_31837-v67_questionnaire-sh14 copy.csv\n",
      "data_exp_31837-v67_questionnaire-sh14.csv\n",
      "data_exp_31837-v70_questionnaire-sh14.csv\n",
      "data_exp_31837-v72_questionnaire-sh14.csv\n",
      "data_exp_31837-v73_questionnaire-sh14.csv\n",
      "data_exp_31837-v76_questionnaire-sh14 (1).csv\n",
      "data_exp_31837-v76_questionnaire-sh14.csv\n",
      "data_exp_31837-v77_questionnaire-sh14.csv\n",
      "dirs:\n",
      "[]\n",
      "subdir\n",
      "/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/AI_Intro(sh14)/Short\n",
      "data_exp_31837-v60_questionnaire-sh14.csv\n",
      "data_exp_31837-v62_questionnaire-sh14.csv\n",
      "data_exp_31837-v64_questionnaire-sh14.csv\n",
      "data_exp_31837-v65_questionnaire-sh14.csv\n",
      "data_exp_31837-v67_questionnaire-sh14 copy.csv\n",
      "data_exp_31837-v67_questionnaire-sh14.csv\n",
      "data_exp_31837-v70_questionnaire-sh14.csv\n",
      "data_exp_31837-v72_questionnaire-sh14.csv\n",
      "data_exp_31837-v73_questionnaire-sh14.csv\n",
      "data_exp_31837-v76_questionnaire-sh14 copy.csv\n",
      "data_exp_31837-v76_questionnaire-sh14.csv\n",
      "data_exp_31837-v77_questionnaire-sh14.csv\n",
      "246\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "AIpath = os.path.join(topFolder, 'AI_Intro(sh14)/')\n",
    "aiDF_short = pd.DataFrame()\n",
    "aiDF_long = pd.DataFrame()\n",
    "\n",
    "for subdir, dirs, files in sorted(os.walk(AIpath)):\n",
    "    dir_name = os.path.basename(os.path.normpath(subdir))\n",
    "    print(\"dirs:\")\n",
    "    print(dirs)\n",
    "    print(\"subdir\")\n",
    "    print(subdir)\n",
    "\n",
    "    if dir_name == \"Long\":\n",
    "        for filename in sorted(files):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                print(filename)\n",
    "                path = os.path.join(subdir,filename)\n",
    "                tmp = pd.read_csv(path)\n",
    "                aiDF_long = pd.concat([aiDF_long,tmp],ignore_index=True)\n",
    "    if dir_name == \"Short\":\n",
    "        for filename in sorted(files):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                print(filename)\n",
    "                path = os.path.join(subdir,filename)\n",
    "                tmp = pd.read_csv(path)\n",
    "                aiDF_short = pd.concat([aiDF_short,tmp],ignore_index=True)\n",
    "                \n",
    "aiDF_short.columns = aiDF_short.columns.str.replace(' ', '')\n",
    "aiDF_short.columns = aiDF_short.columns.str.replace('-', '_')\n",
    "\n",
    "aiDF_long.columns = aiDF_long.columns.str.replace(' ', '')\n",
    "aiDF_long.columns = aiDF_long.columns.str.replace('-', '_')\n",
    "\n",
    "print(len(aiDF_short.ParticipantPrivateID.unique()))\n",
    "print(len(aiDF_long.ParticipantPrivateID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirs:\n",
      "['Short', 'Long']\n",
      "subdir\n",
      "/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/Consent(gzxr)/\n",
      "dirs:\n",
      "[]\n",
      "subdir\n",
      "/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/Consent(gzxr)/Long\n",
      "data_exp_31837-v60_questionnaire-gzxr.csv\n",
      "data_exp_31837-v62_questionnaire-gzxr.csv\n",
      "data_exp_31837-v64_questionnaire-gzxr.csv\n",
      "data_exp_31837-v65_questionnaire-gzxr.csv\n",
      "data_exp_31837-v67_questionnaire-gzxr copy.csv\n",
      "data_exp_31837-v67_questionnaire-gzxr.csv\n",
      "data_exp_31837-v70_questionnaire-gzxr.csv\n",
      "data_exp_31837-v72_questionnaire-gzxr.csv\n",
      "data_exp_31837-v73_questionnaire-gzxr.csv\n",
      "data_exp_31837-v76_questionnaire-gzxr copy.csv\n",
      "data_exp_31837-v76_questionnaire-gzxr.csv\n",
      "data_exp_31837-v77_questionnaire-gzxr.csv\n",
      "dirs:\n",
      "[]\n",
      "subdir\n",
      "/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/Consent(gzxr)/Short\n",
      "data_exp_31837-v60_questionnaire-gzxr.csv\n",
      "data_exp_31837-v62_questionnaire-gzxr.csv\n",
      "data_exp_31837-v64_questionnaire-gzxr.csv\n",
      "data_exp_31837-v65_questionnaire-gzxr.csv\n",
      "data_exp_31837-v67_questionnaire-gzxr copy.csv\n",
      "data_exp_31837-v67_questionnaire-gzxr.csv\n",
      "data_exp_31837-v70_questionnaire-gzxr.csv\n",
      "data_exp_31837-v72_questionnaire-gzxr.csv\n",
      "data_exp_31837-v73_questionnaire-gzxr.csv\n",
      "data_exp_31837-v76_questionnaire-gzxr copy.csv\n",
      "data_exp_31837-v76_questionnaire-gzxr.csv\n",
      "data_exp_31837-v77_questionnaire-gzxr.csv\n",
      "246\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "consentPath = os.path.join(topFolder, 'Consent(gzxr)/')\n",
    "consent_short = pd.DataFrame()\n",
    "consent_long = pd.DataFrame()\n",
    "\n",
    "for subdir, dirs, files in sorted(os.walk(consentPath)):\n",
    "    dir_name = os.path.basename(os.path.normpath(subdir))\n",
    "    print(\"dirs:\")\n",
    "    print(dirs)\n",
    "    print(\"subdir\")\n",
    "    print(subdir)\n",
    "\n",
    "    if dir_name == \"Long\":\n",
    "        for filename in sorted(files):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                print(filename)\n",
    "                path = os.path.join(subdir,filename)\n",
    "                tmp = pd.read_csv(path)\n",
    "                consent_long = pd.concat([consent_long,tmp],ignore_index=True)\n",
    "    if dir_name == \"Short\":\n",
    "        for filename in sorted(files):\n",
    "            if filename.endswith(\".csv\"):\n",
    "                print(filename)\n",
    "                path = os.path.join(subdir,filename)\n",
    "                tmp = pd.read_csv(path)\n",
    "                consent_short = pd.concat([consent_short,tmp],ignore_index=True)\n",
    "                \n",
    "consent_short.columns = consent_short.columns.str.replace(' ', '')\n",
    "consent_short.columns = consent_short.columns.str.replace('-', '_')\n",
    "\n",
    "consent_long.columns = consent_long.columns.str.replace(' ', '')\n",
    "consent_long.columns = consent_long.columns.str.replace('-', '_')\n",
    "\n",
    "print(len(consent_short.ParticipantPrivateID.unique()))\n",
    "print(len(consent_long.ParticipantPrivateID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dirs:\n",
      "[]\n",
      "subdir\n",
      "/Users/byrdsmyth/iCloud/Documents/School/Thesis/Gorilla/feedback/PaidFor/Main_Task\n",
      "246\n",
      "Versions: [60. nan 62. 64. 65. 67. 70. 72. 73. 76. 77.]\n"
     ]
    }
   ],
   "source": [
    "# Combine all main tasks CSVs\n",
    "\n",
    "mainPath = os.path.join(topFolder, 'Main_Task')\n",
    "mainDF = pd.DataFrame()\n",
    "\n",
    "for subdir, dirs, files in sorted(os.walk(mainPath)):\n",
    "    dir_name = os.path.basename(os.path.normpath(subdir))\n",
    "    print(\"dirs:\")\n",
    "    print(dirs)\n",
    "    print(\"subdir\")\n",
    "    print(subdir)\n",
    "\n",
    "    for filename in sorted(files):\n",
    "        if filename.endswith(\".csv\"):\n",
    "#             print(filename)\n",
    "            path = os.path.join(subdir,filename)\n",
    "            if os.path.getsize(path) > 3:\n",
    "#                 print(\"found\")\n",
    "                tmp = pd.read_csv(path)\n",
    "                mainDF = pd.concat([mainDF,tmp],ignore_index=True)\n",
    "        \n",
    "mainDF.columns = mainDF.columns.str.replace(' ', '')\n",
    "mainDF.columns = mainDF.columns.str.replace('-', '_')\n",
    "        \n",
    "print(len(mainDF.ParticipantPrivateID.unique()))\n",
    "print(\"Versions: \" + str(mainDF.ExperimentVersion.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SpreadsheetRow  ScreenNumber ScreenName    ZoneName              ZoneType  \\\n",
      "57            28.0           1.0   Screen 4       Zone6  response_button_text   \n",
      "58            29.0           1.0   Screen 4       Zone7  response_button_text   \n",
      "59            30.0           1.0   Screen 4       Zone7  response_button_text   \n",
      "60            31.0           1.0   Screen 4  NextButton  response_button_text   \n",
      "86            42.0           1.0   Screen 4       Zone6  response_button_text   \n",
      "87            43.0           1.0   Screen 4       Zone7  response_button_text   \n",
      "88            44.0           1.0   Screen 4       Zone7  response_button_text   \n",
      "89            45.0           1.0   Screen 4  NextButton  response_button_text   \n",
      "\n",
      "    ResponseType       Response  Correct  display  \\\n",
      "57           NaN  Somewhat True      0.0  likerts   \n",
      "58           NaN      Very True      0.0  likerts   \n",
      "59           NaN      Very True      0.0  likerts   \n",
      "60           NaN        Neutral      0.0  likerts   \n",
      "86           NaN  Somewhat True      0.0  likerts   \n",
      "87           NaN      Very True      0.0  likerts   \n",
      "88           NaN      Very True      0.0  likerts   \n",
      "89           NaN        Neutral      0.0  likerts   \n",
      "\n",
      "                                                Text1  \n",
      "57  <h3>The charts were helpful in answering the q...  \n",
      "58  <h3>The scenarios shown were helpful in answer...  \n",
      "59  <h3>The blurring of the video was helpful in a...  \n",
      "60  <h3>The information shown was sufficient for u...  \n",
      "86  <h3>The charts were helpful in answering the q...  \n",
      "87  <h3>The scenarios shown were helpful in answer...  \n",
      "88  <h3>The blurring of the video was helpful in a...  \n",
      "89  <h3>The information shown was sufficient for u...  \n"
     ]
    }
   ],
   "source": [
    "pID = \"5fc94c64c8a3e03ded162dd4\"\n",
    "\n",
    "tmp = mainDF[mainDF['ParticipantPublicID']==pID]\n",
    "\n",
    "print(tmp[tmp['display']==\"likerts\"][['SpreadsheetRow', 'ScreenNumber', 'ScreenName', 'ZoneName', 'ZoneType', \\\n",
    "                                      'ResponseType', 'Response',  'Correct',  'display', 'Text1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20.]\n",
      "[0. 1. 2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "# Try numbering qs by filtering carefully\n",
    "mainDF['Question']=0\n",
    "for p_index, pID in enumerate(mainDF.ParticipantPrivateID.unique()):\n",
    "    temp = mainDF[mainDF['ParticipantPrivateID']==pID].copy()\n",
    "    tmp = temp.query('ZoneType==\"response_button_text\" &display!=\"Img_4_Buttons\" &display!=\"likerts\" &display!=\"CompareConfidenceVidOnly\" &display!=\"Attn1\" &display!=\"Attn2\" &display!=\"AttnCheck\" & ScreenNumber==1').copy()\n",
    "    tmp['Question'] = range(1, len(tmp)+1)\n",
    "#     print(tmp.Question.unique())\n",
    "#     print(tmp[['Question','display']])\n",
    "    mainDF.update(tmp['Question'])\n",
    "\n",
    "print(mainDF.Question.unique())\n",
    "\n",
    "# Number the Comparison Questions\n",
    "mainDF['CompConf_Num']=0\n",
    "for p_index, pID in enumerate(mainDF.ParticipantPrivateID.unique()):\n",
    "    temp = mainDF[mainDF['ParticipantPrivateID']==pID].copy()\n",
    "    tmp = temp.query('ZoneType==\"response_button_text\" &display==\"CompareConfidenceVidOnly\"').copy()\n",
    "    tmp['CompConf_Num'] = range(1, len(tmp)+1)\n",
    "#     print(tmp.Question.unique())\n",
    "#     print(tmp[['Question','display']])\n",
    "    mainDF.update(tmp['CompConf_Num'])\n",
    "\n",
    "print(mainDF.CompConf_Num.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SpreadsheetRow</th>\n",
       "      <th>TimeOnRow</th>\n",
       "      <th>ReactionTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157765</td>\n",
       "      <td>157.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.167305</td>\n",
       "      <td>167.305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.408345</td>\n",
       "      <td>408.345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162509</td>\n",
       "      <td>162.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75811</th>\n",
       "      <td>68.0</td>\n",
       "      <td>6.600400</td>\n",
       "      <td>6600.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75812</th>\n",
       "      <td>68.0</td>\n",
       "      <td>6.600400</td>\n",
       "      <td>6600.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75813</th>\n",
       "      <td>68.0</td>\n",
       "      <td>6.600400</td>\n",
       "      <td>6600.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75814</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1240.863000</td>\n",
       "      <td>1.24086e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75815</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75816 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SpreadsheetRow    TimeOnRow ReactionTime\n",
       "0                 NaN          NaN          NaN\n",
       "1                 1.0     0.157765      157.765\n",
       "2                 1.0     0.167305      167.305\n",
       "3                 1.0     0.408345      408.345\n",
       "4                 1.0     0.162509      162.509\n",
       "...               ...          ...          ...\n",
       "75811            68.0     6.600400       6600.4\n",
       "75812            68.0     6.600400       6600.4\n",
       "75813            68.0     6.600400       6600.4\n",
       "75814             NaN  1240.863000  1.24086e+06\n",
       "75815             NaN          NaN          NaN\n",
       "\n",
       "[75816 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mainDF['timeTest'] = mainDF.groupby('ParticipantPublicID')\n",
    "times = np.where(mainDF['ReactionTime']=='LOADING DELAY',0,mainDF['ReactionTime'])\n",
    "mainDF['TimeOnRow'] = times.astype(float)/1000 \n",
    "\n",
    "mainDF[['SpreadsheetRow','TimeOnRow','ReactionTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempDir = '/Volumes/Britt_SSD/ReDoEvals3/'\n",
    "tempTopDir = os.path.join(tempDir, 'UserStudy')\n",
    "if not os.path.isdir(tempTopDir):\n",
    "    os.mkdir(tempTopDir)\n",
    "tempTopDir = os.path.join(tempDir, 'UserStudy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/Britt_SSD/ReDoEvals3/UserStudy\n"
     ]
    }
   ],
   "source": [
    "print(tempTopDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UTCTimestamp     float64\n",
       "ReactionTime      object\n",
       "UTCDate           object\n",
       "LocalDate         object\n",
       "ReactionOnset    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainDF[['UTCTimestamp','ReactionTime','UTCDate','LocalDate','ReactionOnset']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## I DO NOT KNOW IF THIS MESSES STUFF UP!!!!!\n",
    "\n",
    "# mainDF['LocalTimestamp'] = pd.to_timedelta(mainDF['LocalTimestamp']).dt.total_seconds()\n",
    "# mainDF['LocalTimezone'] = pd.to_timedelta(mainDF['LocalTimezone']).dt.total_seconds()\n",
    "\n",
    "# mainDF['UTCTimestamp'] = mainDF['UTCTimestamp']/1000\n",
    "\n",
    "# # mainDF['ReactionTime'] = mainDF['ReactionTime'].astype('float64')\n",
    "# mainDF['UTCDate'] = mainDF['UTCDate'].astype('datetime64[s]')\n",
    "# mainDF['LocalDate'] = mainDF['LocalDate'].astype('datetime64[s]')\n",
    "# mainDF['ReactionOnset'] = mainDF['ReactionOnset'].astype('datetime64[s]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainDF['ReactionTime'] = mainDF['ReactionTime'].fillna(0)\n",
    "mainDF['ReactionTime'].replace('LOADING DELAY',0,inplace=True)\n",
    "mainDF['ReactionTime'] = mainDF['ReactionTime'].astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SpreadsheetRow  ScreenNumber ScreenName    ZoneName              ZoneType  \\\n",
      "57            28.0           1.0   Screen 4       Zone6  response_button_text   \n",
      "58            29.0           1.0   Screen 4       Zone7  response_button_text   \n",
      "59            30.0           1.0   Screen 4       Zone7  response_button_text   \n",
      "60            31.0           1.0   Screen 4  NextButton  response_button_text   \n",
      "86            42.0           1.0   Screen 4       Zone6  response_button_text   \n",
      "87            43.0           1.0   Screen 4       Zone7  response_button_text   \n",
      "88            44.0           1.0   Screen 4       Zone7  response_button_text   \n",
      "89            45.0           1.0   Screen 4  NextButton  response_button_text   \n",
      "\n",
      "    ResponseType       Response  Correct  display  \\\n",
      "57           NaN  Somewhat True      0.0  likerts   \n",
      "58           NaN      Very True      0.0  likerts   \n",
      "59           NaN      Very True      0.0  likerts   \n",
      "60           NaN        Neutral      0.0  likerts   \n",
      "86           NaN  Somewhat True      0.0  likerts   \n",
      "87           NaN      Very True      0.0  likerts   \n",
      "88           NaN      Very True      0.0  likerts   \n",
      "89           NaN        Neutral      0.0  likerts   \n",
      "\n",
      "                                                Text1  \n",
      "57  <h3>The charts were helpful in answering the q...  \n",
      "58  <h3>The scenarios shown were helpful in answer...  \n",
      "59  <h3>The blurring of the video was helpful in a...  \n",
      "60  <h3>The information shown was sufficient for u...  \n",
      "86  <h3>The charts were helpful in answering the q...  \n",
      "87  <h3>The scenarios shown were helpful in answer...  \n",
      "88  <h3>The blurring of the video was helpful in a...  \n",
      "89  <h3>The information shown was sufficient for u...  \n"
     ]
    }
   ],
   "source": [
    "pID = \"5fc94c64c8a3e03ded162dd4\"\n",
    "\n",
    "tmp = mainDF[mainDF['ParticipantPublicID']==pID]\n",
    "\n",
    "print(tmp[tmp['display']==\"likerts\"][['SpreadsheetRow', 'ScreenNumber', 'ScreenName', 'ZoneName', 'ZoneType', \\\n",
    "                                      'ResponseType', 'Response',  'Correct',  'display', 'Text1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Main Task DF to parquet:\n",
    "filePath = os.path.join(tempTopDir, 'GP_Main.parquet')\n",
    "# mainDF.to_parquet(path=filePath,compression='brotli')\n",
    "\n",
    "table = pa.Table.from_pandas(mainDF, safe=False)\n",
    "# Parquet with Brotli compression\n",
    "pq.write_table(table, filePath, compression='BROTLI')\n",
    "\n",
    "filePath = os.path.join(tempTopDir, 'GP_Main.csv')\n",
    "mainDF.to_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write questionnaires to parquets\n",
    "short_list = [demoDF_short, aiDF_short, consent_short]\n",
    "\n",
    "parquetNames = ['GP_Demographics_Short.parquet',\n",
    "               'GP_AI_Short.parquet',\n",
    "               'GP_Consent_Short.parquet']\n",
    "\n",
    "csvNames = ['GP_Demographics_Short.csv',\n",
    "               'GP_AI_Short.csv',\n",
    "               'GP_Consent_Short.csv']\n",
    "\n",
    "for s_index, s in enumerate(short_list):\n",
    "    ### Write Demographics DFs to parquet: \n",
    "    table = pa.Table.from_pandas(s)\n",
    "    # Parquet with Brotli compression\n",
    "    filePath = os.path.join(tempTopDir, parquetNames[s_index])\n",
    "    pq.write_table(table, filePath, compression='BROTLI')\n",
    "    \n",
    "    filePath = os.path.join(tempTopDir, csvNames[s_index])\n",
    "    s.to_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write questionnaires to parquets\n",
    "long_list = [demoDF_long, aiDF_long, consent_long]\n",
    "\n",
    "parquetNames = ['GP_Demographics_Long.parquet',\n",
    "               'GP_AI_Long.parquet',\n",
    "               'GP_Consent_Long.parquet']\n",
    "\n",
    "csvNames = ['GP_Demographics_Long.csv',\n",
    "               'GP_AI_Long.csv',\n",
    "               'GP_Consent_Long.csv']\n",
    "for l_index, l in enumerate(long_list):\n",
    "    ### Write Demographics DFs to parquet: \n",
    "    table = pa.Table.from_pandas(l)\n",
    "    # Parquet with Brotli compression\n",
    "    filePath = os.path.join(tempTopDir, parquetNames[l_index])\n",
    "    pq.write_table(table, filePath, compression='BROTLI')\n",
    "\n",
    "    filePath = os.path.join(tempTopDir, csvNames[l_index])\n",
    "    l.to_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
