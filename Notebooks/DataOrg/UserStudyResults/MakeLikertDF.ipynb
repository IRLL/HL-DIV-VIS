{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import statistics\n",
    "from collections import Counter\n",
    "import pyarrow as pa\n",
    "# import pyarrow.parquet as pq\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp as mc\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempTopDir = '/Volumes/Britt_SSD/ReDoEvals3/UserStudy/'\n",
    "filePath = os.path.join(tempTopDir, 'GP_Main.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249\n"
     ]
    }
   ],
   "source": [
    "taskDF = pd.read_parquet(filePath)\n",
    "taskDF['ParticipantNum'] = taskDF[\"ParticipantPrivateID\"]\n",
    "taskDF = taskDF.astype({\"ParticipantPrivateID\": str})\n",
    "filePath = os.path.join(tempTopDir, 'GP_Main_Short.parquet')\n",
    "slimDF = pd.read_parquet(filePath)\n",
    "print(len(slimDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = os.path.join(tempTopDir, 'GP_Consent_Long.parquet')\n",
    "consentDF_L = pd.read_parquet(filePath).infer_objects()\n",
    "consentDF_L = consentDF_L.astype({\"ParticipantPrivateID\": str})\n",
    "# drop rows where NAN in participant private id\n",
    "consentDF_L = consentDF_L[consentDF_L['ParticipantPrivateID'].notna()]\n",
    "\n",
    "filePath = os.path.join(tempTopDir, 'GP_Consent_Short.parquet')\n",
    "consentDF_S = pd.read_parquet(filePath).infer_objects()\n",
    "consentDF_S = consentDF_S.astype({\"ParticipantPrivateID\": str})\n",
    "# drop rows where NAN in participant private id\n",
    "consentDF_S = consentDF_S[consentDF_S['ParticipantPrivateID'].notna()]\n",
    "\n",
    "filePath = os.path.join(tempTopDir, 'GP_Demographics_Long.parquet')\n",
    "demoDF_L = pd.read_parquet(filePath).infer_objects()\n",
    "demoDF_L = demoDF_L.astype({\"ParticipantPrivateID\": str})\n",
    "# drop rows where NAN in participant private id\n",
    "demoDF_L = demoDF_L[demoDF_L['ParticipantPrivateID'].notna()]\n",
    "\n",
    "filePath = os.path.join(tempTopDir, 'GP_Demographics_Short.parquet')\n",
    "demoDF_S = pd.read_parquet(filePath).infer_objects()\n",
    "demoDF_S = demoDF_S.astype({\"ParticipantPrivateID\": str})\n",
    "# drop rows where NAN in participant private id\n",
    "demoDF_S = demoDF_S[demoDF_S['ParticipantPrivateID'].notna()]\n",
    "\n",
    "filePath = os.path.join(tempTopDir, 'GP_AI_Long.parquet')\n",
    "aiDF_L = pd.read_parquet(filePath).infer_objects()\n",
    "aiDF_L = aiDF_L.astype({\"ParticipantPrivateID\": str})\n",
    "# drop rows where NAN in participant private id\n",
    "aiDF_L = aiDF_L[aiDF_L['ParticipantPrivateID'].notna()]\n",
    "\n",
    "filePath = os.path.join(tempTopDir, 'GP_AI_Short.parquet')\n",
    "aiDF_S = pd.read_parquet(filePath).infer_objects()\n",
    "aiDF_S = aiDF_S.astype({\"ParticipantPrivateID\": str})\n",
    "# drop rows where NAN in participant private id\n",
    "aiDF_S = aiDF_S[aiDF_S['ParticipantPrivateID'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245\n",
      "[60. 62. 64. 65. 67. 70. 72. 73. 76. 77.]\n",
      "['APPROVED' 'RETURNED' 'REJECTED']\n",
      "['APPROVED']\n",
      "['5f5b7c0c291dc62b000bb637' '5f57a42b46df8927414990fc'\n",
      " '601f23aa1dc6d94683bde1ff' '5fcb5f768c4bb789f899288f'\n",
      " '60342dbfcf15a5092cda30dc' '5bce1cf2ac6b660001908ab8'\n",
      " '5f102f0212ea4f000a8ac9da' '600ac30a0e8a51025de63b95'\n",
      " '5f40d6c251a8cd21d01b6f40' '6034f9fe12d7b21679665d41'\n",
      " '5eccd97f6ce039000b2a61f2' '5ca14d419ca7f60017258fc6'\n",
      " '5f8dcac25e91d312a21a625f']\n",
      "232\n",
      "232\n"
     ]
    }
   ],
   "source": [
    "print(len(slimDF.ParticipantPublicID.unique()))\n",
    "\n",
    "# drop particpants who have not been accepted (rejected or timed out)\n",
    "# options: approved, awaiting review,rejected, returned, timed-out\n",
    "print(slimDF.ExperimentVersion.unique())\n",
    "print(slimDF.status.unique())\n",
    "# get names of indexes for which to drop\n",
    "pID_removed1 = slimDF[(slimDF['status']=='REJECTED') | \n",
    "                      (slimDF['status']=='RETURNED')].ParticipantPublicID.unique()\n",
    "pID_removed2 = slimDF[(slimDF['status']=='REJECTED')].ParticipantPublicID.unique()\n",
    "index_names = slimDF[(slimDF['status']!='AWAITING REVIEW') & (slimDF['status']!='APPROVED')].index\n",
    "  \n",
    "# drop these given row\n",
    "# indexes from dataFrame\n",
    "\n",
    "# tmp_slimDF = slimDF[~slimDF['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "print(tmp_slimDF.status.unique())\n",
    "print(pID_removed1)\n",
    "    \n",
    "tmp_demoDF_L = demoDF_L[~demoDF_L['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "tmp_demoDF_S = demoDF_S[~demoDF_S['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "\n",
    "tmp_consentDF_L = consentDF_L[~consentDF_L['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "tmp_consentDF_S = consentDF_S[~consentDF_S['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "\n",
    "tmp_aiDF_L = aiDF_L[~aiDF_L['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "tmp_aiDF_S = aiDF_S[~aiDF_S['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "\n",
    "tmp_taskDF = taskDF[~taskDF['ParticipantPublicID'].isin(pID_removed1)].copy()\n",
    "tmp_slimDF = slimDF[slimDF['ParticipantPublicID'].isin(tmp_taskDF.ParticipantPublicID.unique())].copy()\n",
    "# print(tmp_taskDF[tmp_taskDF['ParticipantPublicID']==pID_removed1[-3]])\n",
    "\n",
    "print(len(tmp_slimDF.ParticipantPublicID.unique()))\n",
    "print(len(tmp_taskDF.ParticipantPublicID.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "likertDF = tmp_taskDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h3>The_charts_were_helpful_in_answering_the\n",
      "<h3>The_scenarios_shown_were_helpful_in_answering\n",
      "<h3>The_blurring_of_the_video_was_helpful\n",
      "<h3>The_information_shown_was_sufficient_for_understanding\n",
      "<h3>The_charts_contained_sufficient_detail_for_me\n",
      "_<h3>The_charts_contained_irrelevant_or_distracting\n",
      "<h3>The_charts_contained_irrelevant_or_distracting_details.</h3>\n",
      "<h3>The_scenarios_contained_irrelevant_or_distracting_details.</h3>\n",
      "['charts_helpful_1' 'scenarios_helpful_1' 'blurring_helpful_1'\n",
      " 'info_sufficient_1' 'charts_helpful_2' 'scenarios_helpful_2'\n",
      " 'blurring_helpful_2' 'info_sufficient_2' 'irrelevant_distracting_1'\n",
      " 'irrelevant_distracting_2']\n",
      "index\n",
      "57          charts_helpful_1\n",
      "58       scenarios_helpful_1\n",
      "59        blurring_helpful_1\n",
      "60         info_sufficient_1\n",
      "86          charts_helpful_2\n",
      "                ...         \n",
      "75565     blurring_helpful_1\n",
      "75570      info_sufficient_1\n",
      "75635    scenarios_helpful_2\n",
      "75640     blurring_helpful_2\n",
      "75645      info_sufficient_2\n",
      "Name: likertName, Length: 1500, dtype: object\n",
      "index\n",
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "75810    0\n",
      "75811    0\n",
      "75812    0\n",
      "75813    0\n",
      "75814    0\n",
      "Name: likertName, Length: 70263, dtype: object\n"
     ]
    }
   ],
   "source": [
    "## BREAK THE TEXT INTO BITS TO NAME THE LIKERTS ##\n",
    "\n",
    "likertDF['likertName'] = 0\n",
    "\n",
    "tmp = likertDF.query('Likert_Num!=0 & ZoneType == \"response_button_text\"')\n",
    "\n",
    "new = tmp['Text1'].str.split(\" \", n = 10, expand = True)\n",
    "\n",
    "# now, make a new column and then update in main DF\n",
    "\n",
    "tmp['likertName'] = new[0]+\"_\"+new[1]+\"_\"+new[2]+\"_\"+new[3]+\"_\"+new[4]+\"_\"+new[5]+\"_\"+new[6]\n",
    "ls = tmp['likertName'].unique().tolist()\n",
    "for i in ls:\n",
    "    print(i)\n",
    "tmp['likertName'] = tmp['likertName'].str.replace('<h3>The_charts_were_helpful_in_answering_the', \\\n",
    "                                                  'charts_helpful',regex=True)\n",
    "\n",
    "tmp['likertName'] = tmp['likertName'].str.replace('<h3>The_scenarios_shown_were_helpful_in_answering', \\\n",
    "                                                  'scenarios_helpful',regex=True)\n",
    "\n",
    "tmp['likertName'] = tmp['likertName'].str.replace('<h3>The_blurring_of_the_video_was_helpful', \\\n",
    "                                                  'blurring_helpful',regex=True)\n",
    "\n",
    "tmp['likertName'] = tmp['likertName'].str.replace('<h3>The_charts_contained_sufficient_detail_for_me', \\\n",
    "                                                  'charts_helpful',regex=True)\n",
    "\n",
    "tmp['likertName'] = tmp['likertName'].str.replace('_<h3>The_charts_contained_irrelevant_or_distracting', \\\n",
    "                                                  'irrelevant_distracting',regex=True)\n",
    "\n",
    "tmp['likertName'] = tmp['likertName'].str.replace('<h3>The_information_shown_was_sufficient_for_understanding', \\\n",
    "                                                  'info_sufficient',regex=True)\n",
    "\n",
    "tmp['likertName'] = tmp['likertName'].str.replace( \\\n",
    "                                          '<h3>The_charts_contained_irrelevant_or_distracting_details.</h3>', \\\n",
    "                                                  'irrelevant_distracting',regex=True)\n",
    "\n",
    "tmp['likertName'] = tmp['likertName'].str.replace( \\\n",
    "                                          '<h3>The_scenarios_contained_irrelevant_or_distracting_details.</h3>', \\\n",
    "                                                  'irrelevant_distracting',regex=True)\n",
    "\n",
    "tmp['likertName'] = np.where(tmp['AgentNum'].astype(int) == 1, tmp['likertName'] + \"_1\",\n",
    "                             np.where(tmp['AgentNum'].astype(int) == 2, tmp['likertName'] + \"_2\",\n",
    "                                      tmp['likertName'] + \"_0\"))\n",
    "                             \n",
    "\n",
    "print(tmp['likertName'].unique())\n",
    "\n",
    "likertDF['likertName'].update(tmp['likertName'])\n",
    "\n",
    "print(likertDF.query('Likert_Num!=0')['likertName'])\n",
    "\n",
    "print(likertDF.query('Likert_Num==0')['likertName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################Pull out the rows we need with just the likerts info#####################\n",
    "tmp1 = likertDF[['Response', 'likertName', 'ParticipantPublicID','ZoneType','display']].query('likertName!=0 & ZoneType == \"response_button_text\"')\n",
    "tmp1['Response'] = pd.Categorical(tmp1['Response'])\n",
    "tmp1 = tmp1.dropna()\n",
    "# print(len(tmp1[tmp1['ParticipantPublicID']==pID].query('display==\"likerts\"')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# first filter down to only irrelevant:\n",
    "tmp2 = tmp1.query('likertName==\"irrelevant_distracting_1\" | likertName==\"irrelevant_distracting_2\"')\n",
    "codes = {'Very False':'Very True','Somewhat False':'Somewhat True', \\\n",
    "         'Neutral':'Neutral','Somewhat True':'Somewhat False','Very True':'Very False'}\n",
    "\n",
    "# Now use map on sub-df to swap negative q sentiments\n",
    "tmp2['Response1'] = tmp2['Response'].map(codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the swapped sentiments back to the original DF\n",
    "tmp1['Response'].update(tmp2['Response1'])\n",
    "# print(len(tmp1[tmp1['ParticipantPublicID']==pID].query('display==\"likerts\"')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use mapping to make numeric column\n",
    "codes = {'Very False':1,'Somewhat False':2, 'Neutral':3,'Somewhat True':4,'Very True':5}\n",
    "tmp1['NumericResponse'] = tmp1['Response'].map(codes)\n",
    "# print(len(tmp1[tmp1['ParticipantPublicID']==pID].query('display==\"likerts\"')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And update main DF with information\n",
    "likertDF['Response'].update(tmp1['Response'])\n",
    "likertDF['NumericResponse']=0\n",
    "likertDF['NumericResponse'].update(tmp1['NumericResponse'])\n",
    "# likertDF = pd.merge(likertDF,tmp1[['NumericResponse', 'ParticipantPublicID','ZoneType','display']], on=['ZoneType','ParticipantPublicID','display'],how=\"left\")\n",
    "# print(len(likertDF[likertDF['ParticipantPublicID']==pID].query('display==\"likerts\"')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      "71763\n"
     ]
    }
   ],
   "source": [
    "# Copy these so we can start over from here if needed\n",
    "\n",
    "likertSlim = tmp_slimDF.copy()\n",
    "likertDF2 = likertDF.copy()\n",
    "\n",
    "print(len(likertSlim))\n",
    "print(len(likertDF2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None 'content_video' 'continue_button' 'response_button_text'\n",
      " 'response_text_area' 'response_rating_scale_likert_active'\n",
      " 'response_rating_scale_likert']\n",
      "       NumericResponse           likertName       ParticipantPublicID\n",
      "index                                                                \n",
      "57                 4.0     charts_helpful_1  5fc94c64c8a3e03ded162dd4\n",
      "58                 5.0  scenarios_helpful_1  5fc94c64c8a3e03ded162dd4\n",
      "59                 5.0   blurring_helpful_1  5fc94c64c8a3e03ded162dd4\n",
      "60                 3.0    info_sufficient_1  5fc94c64c8a3e03ded162dd4\n",
      "86                 4.0     charts_helpful_2  5fc94c64c8a3e03ded162dd4\n",
      "...                ...                  ...                       ...\n",
      "75565              3.0   blurring_helpful_1  5ed57ec8141d24118731f1bc\n",
      "75570              4.0    info_sufficient_1  5ed57ec8141d24118731f1bc\n",
      "75635              4.0  scenarios_helpful_2  5ed57ec8141d24118731f1bc\n",
      "75640              4.0   blurring_helpful_2  5ed57ec8141d24118731f1bc\n",
      "75645              4.0    info_sufficient_2  5ed57ec8141d24118731f1bc\n",
      "\n",
      "[1500 rows x 3 columns]\n",
      "likertName       ParticipantPublicID  blurring_helpful_1  blurring_helpful_2  \\\n",
      "0           55bac673fdf99b554657f2d6                 2.0                 3.0   \n",
      "1           55cf7e8b34e906000ee56498                 2.0                 1.0   \n",
      "2           56db8f127dcddf000dd592af                 2.0                 2.0   \n",
      "3           572f1c1d3c27e7000f0b31aa                 NaN                 NaN   \n",
      "4           596e1edd39e9d00001b7bb98                 NaN                 NaN   \n",
      "\n",
      "likertName  charts_helpful_1  charts_helpful_2  info_sufficient_1  \\\n",
      "0                        NaN               NaN                3.0   \n",
      "1                        2.0               2.0                2.0   \n",
      "2                        3.0               4.0                2.0   \n",
      "3                        3.0               3.0                4.0   \n",
      "4                        4.0               4.0                3.0   \n",
      "\n",
      "likertName  info_sufficient_2  irrelevant_distracting_1  \\\n",
      "0                         3.0                       NaN   \n",
      "1                         2.0                       NaN   \n",
      "2                         2.0                       NaN   \n",
      "3                         2.0                       3.0   \n",
      "4                         3.0                       2.0   \n",
      "\n",
      "likertName  irrelevant_distracting_2  scenarios_helpful_1  scenarios_helpful_2  \n",
      "0                                NaN                  3.0                  3.0  \n",
      "1                                NaN                  2.0                  3.0  \n",
      "2                                NaN                  3.0                  4.0  \n",
      "3                                3.0                  NaN                  NaN  \n",
      "4                                2.0                  NaN                  NaN  \n",
      "['ParticipantPrivateID', 'difficulty', 'visuals', 'agents', 'QsTotal', 'QsCorrect', 'Agent_QsTotal', 'Agent_QsCorrect', 'Agent_QsWO_GhostsTotal', 'Agent_QsWO_GhostsCorrect', 'Qs1_Correct', 'Qs2_Correct', 'QsPart_Total', 'predictionsCorrect', 'predictionsTotal', 'predictions1Correct', 'predictions2Correct', 'predictionsHalfTotal', 'regionsCorrect', 'regionsTotal', 'regions1Correct', 'regions2Correct', 'regionsHalfTotal', 'levelCorrect', 'levelTotal', 'level1Correct', 'level2Correct', 'levelHalfTotal', 'ghostsCorrect', 'ghostsTotal', 'ghosts1Correct', 'ghosts2Correct', 'ghostsHalfTotal', 'comparisonsCorrect', 'comparisonsTotal', 'timeTakenMain_All', 'timeTakenMain_AgentsOnly', 'timeTaken_Consent', 'timeTaken_Demographics', 'timeTaken_AI', 'timeTaken_Agent1', 'timeTaken_Agent2', 'timeTaken_Agent3', 'time_TOTAL', 'vidPlayed', 'avgVidPlays', 'ratioVidPlaysToAvg', 'ExperimentVersion_x', 'totPerc', 'agTotPerc', 'tot1Perc', 'tot2Perc', 'Agent_QsWO_GhostsPerc', 'predPerc', 'pred1Perc', 'pred2Perc', 'regPerc', 'reg1Perc', 'reg2Perc', 'lvlPerc', 'lvl1Perc', 'lvl2Perc', 'ghostPerc', 'ghost1Perc', 'ghost2Perc', 'compPerc', 'TreeNodeKey_x', 'age_info', 'age_info_text', 'age_info_quantised', 'gender_id', 'gender_id_text', 'gender_id_quantised', 'education_level', 'education_level_text', 'education_level_quantised', 'ExperimentVersion', 'ParticipantPublicID', 'ai_involvement_1', 'ai_involvement_2', 'ai_involvement_3', 'ai_involvement_4', 'ai_involvement_5', 'ai_involvement_6', 'ai_involvement_text', 'ai_involvement_other', 'ai_opinion', 'ai_opinion_quantised', 'AI_longForm', 'pacman_experience', 'pacman_experience_text', 'pacman_experience_quantised', 'ProlificName', 'status', 'age', 'num_approvals', 'num_rejections', 'prolific_score', 'Country of Birth', 'Current Country of Residence', 'Employment Status', 'First Language', 'Fluent languages', 'Gender identity', 'Nationality', 'Sex', 'Student Status', 'Suspicious', 'AmtPaid', 'Notes', 'Quality Rating(1-10)', 'Part1', 'Part2', 'Part3', 'MediaAI', 'HomeAI', 'AtWorkAI', 'ClassOnAI', 'DevelopAI', 'NoneAI', 'OtherAI']\n",
      "['ParticipantPublicID', 'blurring_helpful_1', 'blurring_helpful_2', 'charts_helpful_1', 'charts_helpful_2', 'info_sufficient_1', 'info_sufficient_2', 'irrelevant_distracting_1', 'irrelevant_distracting_2', 'scenarios_helpful_1', 'scenarios_helpful_2']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Need to add to slimDF... User's numeric response, and user's normalized response, for each.\n",
    "print(tmp_taskDF.ZoneType.unique())\n",
    "\n",
    "df_LikertPivot = likertDF2.query('likertName!=0 & ZoneType == \"response_button_text\"')[['NumericResponse', 'likertName','ParticipantPublicID']]\n",
    "df_LikertPivot.drop_duplicates(['likertName','ParticipantPublicID'],inplace=True)\n",
    "print(df_LikertPivot)\n",
    "\n",
    "df_LikertPivot.set_index(['ParticipantPublicID'], append=True)\n",
    "tmp2 =  df_LikertPivot[['NumericResponse', 'likertName','ParticipantPublicID']].pivot(index='ParticipantPublicID', columns=['likertName'], values='NumericResponse')\n",
    "tmp2 = tmp2.reset_index()\n",
    "\n",
    "print(tmp2.head(5))\n",
    "print(likertSlim.columns.tolist())\n",
    "print(tmp2.columns.tolist())\n",
    "\n",
    "likertSlim = pd.merge(likertSlim,tmp2[['ParticipantPublicID', 'blurring_helpful_1', \\\n",
    "      'blurring_helpful_2', 'charts_helpful_1', 'charts_helpful_2', 'info_sufficient_1', 'info_sufficient_2', 'irrelevant_distracting_1', \\\n",
    "      'irrelevant_distracting_2', 'scenarios_helpful_1', 'scenarios_helpful_2']], \\\n",
    "                on='ParticipantPublicID',how=\"left\")\n",
    "\n",
    "# print(likertSlim[likertSlim['ParticipantPublicID']==pID][['ParticipantPublicID', 'blurring_helpful_1', \\\n",
    "#       'blurring_helpful_2', 'charts_helpful_1', 'charts_helpful_2', 'info_sufficient_1', 'info_sufficient_2', 'irrelevant_distracting_1', \\\n",
    "#       'irrelevant_distracting_2', 'scenarios_helpful_1', 'scenarios_helpful_2']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "232\n",
      "     blurring_helpful_1  blurring_helpful_2  charts_helpful_1  \\\n",
      "0                   5.0                 5.0               4.0   \n",
      "1                   NaN                 NaN               4.0   \n",
      "2                   1.0                 4.0               NaN   \n",
      "3                   1.0                 1.0               3.0   \n",
      "4                   2.0                 3.0               1.0   \n",
      "..                  ...                 ...               ...   \n",
      "227                 2.0                 2.0               NaN   \n",
      "228                 NaN                 NaN               3.0   \n",
      "229                 4.0                 4.0               4.0   \n",
      "230                 NaN                 NaN               4.0   \n",
      "231                 3.0                 4.0               NaN   \n",
      "\n",
      "     charts_helpful_2  info_sufficient_1  info_sufficient_2  \\\n",
      "0                 4.0                3.0                3.0   \n",
      "1                 4.0                4.0                4.0   \n",
      "2                 NaN                2.0                4.0   \n",
      "3                 2.0                2.0                3.0   \n",
      "4                 2.0                1.0                1.0   \n",
      "..                ...                ...                ...   \n",
      "227               NaN                5.0                4.0   \n",
      "228               2.0                4.0                2.0   \n",
      "229               4.0                4.0                4.0   \n",
      "230               4.0                4.0                3.0   \n",
      "231               NaN                4.0                4.0   \n",
      "\n",
      "     irrelevant_distracting_1  irrelevant_distracting_2  scenarios_helpful_1  \\\n",
      "0                         NaN                       NaN                  5.0   \n",
      "1                         2.0                       2.0                  NaN   \n",
      "2                         NaN                       NaN                  2.0   \n",
      "3                         NaN                       NaN                  2.0   \n",
      "4                         NaN                       NaN                  4.0   \n",
      "..                        ...                       ...                  ...   \n",
      "227                       NaN                       NaN                  5.0   \n",
      "228                       4.0                       3.0                  NaN   \n",
      "229                       NaN                       NaN                  4.0   \n",
      "230                       3.0                       3.0                  NaN   \n",
      "231                       NaN                       NaN                  3.0   \n",
      "\n",
      "     scenarios_helpful_2  \n",
      "0                    5.0  \n",
      "1                    NaN  \n",
      "2                    4.0  \n",
      "3                    4.0  \n",
      "4                    2.0  \n",
      "..                   ...  \n",
      "227                  4.0  \n",
      "228                  NaN  \n",
      "229                  4.0  \n",
      "230                  NaN  \n",
      "231                  4.0  \n",
      "\n",
      "[232 rows x 10 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      5.0\n",
      "1      4.0\n",
      "2      4.0\n",
      "3      2.0\n",
      "4      1.0\n",
      "      ... \n",
      "227    4.0\n",
      "228    3.0\n",
      "229    4.0\n",
      "230    3.0\n",
      "231    4.0\n",
      "Name: likertMode, Length: 232, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      5.0\n",
      "1      4.0\n",
      "2      2.0\n",
      "3      2.0\n",
      "4      1.0\n",
      "      ... \n",
      "227    5.0\n",
      "228    4.0\n",
      "229    4.0\n",
      "230    4.0\n",
      "231    3.0\n",
      "Name: likert1Mode, Length: 232, dtype: float64\n",
      "0      5.0\n",
      "1      4.0\n",
      "2      4.0\n",
      "3      2.0\n",
      "4      2.0\n",
      "      ... \n",
      "227    4.0\n",
      "228    2.0\n",
      "229    4.0\n",
      "230    3.0\n",
      "231    4.0\n",
      "Name: likert2Mode, Length: 232, dtype: float64\n",
      "232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Get mode of likert anwsers on 1, 2, and overall\n",
    "\n",
    "tmp = likertSlim.copy()\n",
    "print(len(likertSlim))\n",
    "tmp1 = tmp[['blurring_helpful_1', \\\n",
    "      'blurring_helpful_2', 'charts_helpful_1', 'charts_helpful_2', 'info_sufficient_1', 'info_sufficient_2', 'irrelevant_distracting_1', \\\n",
    "      'irrelevant_distracting_2', 'scenarios_helpful_1', 'scenarios_helpful_2']]\n",
    "print(tmp1)\n",
    "tmp1['likertMode'] = np.where(tmp1.mode(axis=1)[2].notnull(),tmp1.mode(axis=1)[1],tmp1.mode(axis=1)[0])\n",
    "# tmp1['likertMode'] = tmp1.mode(axis=1)\n",
    "print(tmp1['likertMode'])\n",
    "\n",
    "tmp2 = tmp1[['blurring_helpful_1', 'charts_helpful_1', 'info_sufficient_1', 'irrelevant_distracting_1', \\\n",
    "      'scenarios_helpful_1']]\n",
    "\n",
    "tmp1['likert1Mode'] = np.where(tmp2.mode(axis=1)[2].notnull(),tmp2.mode(axis=1)[1],tmp2.mode(axis=1)[0])\n",
    "# tmp1['likert1Mode'] = tmp2.mode(axis=1)\n",
    "print(tmp1['likert1Mode'])\n",
    "\n",
    "tmp2 = tmp1[['blurring_helpful_2', 'charts_helpful_2', 'info_sufficient_2', 'irrelevant_distracting_2', \\\n",
    "      'scenarios_helpful_2']]\n",
    "\n",
    "tmp1['likert2Mode'] = np.where(tmp2.mode(axis=1)[2].notnull(),tmp2.mode(axis=1)[1],tmp2.mode(axis=1)[0])\n",
    "# tmp1['likert2Mode'] = tmp2.mode(axis=1)\n",
    "print(tmp1['likert2Mode'])\n",
    "\n",
    "likertSlim['likertMode'] = tmp1['likertMode']\n",
    "likertSlim['likert1Mode'] = tmp1['likert1Mode']\n",
    "likertSlim['likert2Mode'] = tmp1['likert2Mode']\n",
    "\n",
    "print(len(likertSlim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Response  Correct  Question       ParticipantPublicID  \\\n",
      "index                                                                    \n",
      "101        Agent Thompson      0.0      17.0  5fc94c64c8a3e03ded162dd4   \n",
      "102    Somewhat Confident      0.0       0.0  5fc94c64c8a3e03ded162dd4   \n",
      "107         Agent Jackson      1.0      18.0  5fc94c64c8a3e03ded162dd4   \n",
      "108               Neutral      0.0       0.0  5fc94c64c8a3e03ded162dd4   \n",
      "\n",
      "       CompConf_Num  \n",
      "index                \n",
      "101             0.0  \n",
      "102             1.0  \n",
      "107             0.0  \n",
      "108             2.0  \n",
      "['Somewhat Confident', 'Neutral', 'Not Confident', 'Completely Confident', 'Not at All Confident']\n",
      "Categories (11, object): ['Agent Jackson', 'Agent Jones', 'Agent Smith', 'Agent Thompson', ..., 'Neutral', 'Not Confident', 'Not at All Confident', 'Somewhat Confident']\n",
      "       likertName       ParticipantPublicID  NumericResponse\n",
      "index                                                       \n",
      "101          17.0  5fc94c64c8a3e03ded162dd4              4.0\n",
      "107          18.0  5fc94c64c8a3e03ded162dd4              3.0\n",
      "122          19.0  5fc94c64c8a3e03ded162dd4              4.0\n",
      "141          20.0  5fc94c64c8a3e03ded162dd4              3.0\n",
      "289          17.0  5f4557043bf01d125f02f01a              4.0\n",
      "311          18.0  5f4557043bf01d125f02f01a              4.0\n",
      "344          19.0  5f4557043bf01d125f02f01a              4.0\n"
     ]
    }
   ],
   "source": [
    "## Make DF for answers to comparisons\n",
    "df_CompPivot = tmp_taskDF.query('AgentNum==3 & (Question!=0 | CompConf_Num!=0)')[['Response','Correct','Question', \\\n",
    "                                                              'ParticipantPublicID', 'CompConf_Num']]\n",
    "thisDF = slimDF.copy()\n",
    "df_CompPivot['Response'] = pd.Categorical(df_CompPivot.Response)\n",
    "print(df_CompPivot.head(4))\n",
    "\n",
    "#move confcatvar and compconf up one\n",
    "df_CompPivot['Response'] = df_CompPivot['Response'].shift(-1)\n",
    "df_CompPivot['CompConf_Num'] = df_CompPivot['CompConf_Num'].shift(-1)\n",
    "# df_CompPivot['confCatVar'] = df_CompPivot['confCatVar'].shift(-1)\n",
    "df_CompPivot = df_CompPivot.query('Question!=0').dropna().rename(columns={'Question': \"likertName\"}).drop(columns=['CompConf_Num','Correct'])\n",
    "print(df_CompPivot.Response.unique())\n",
    "\n",
    "codes = {'Not at All Confident':1,'Not Confident':2, \\\n",
    "         'Neutral':3,'Somewhat Confident':4,'Completely Confident':5}\n",
    "# Now use map on sub-df to swap negative q sentiments\n",
    "df_CompPivot['NumericResponse'] = df_CompPivot['Response'].map(codes)\n",
    "df_CompPivot.drop('Response', axis=1, inplace=True)\n",
    "print(df_CompPivot.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5f653485fa6c900b6548f35c\n",
      "5ce7046a9390750017b64ac6\n",
      "5ebbe8e3c1aef8016cc78ca1\n",
      "604b528b95d6d998726f0bd9\n",
      "5afdb5993eb22c00019bb339\n",
      "['index', 'ParticipantPublicID', 'likertName', 'Z_Scores']\n"
     ]
    }
   ],
   "source": [
    "# Now we need to get zscores:\n",
    "newDF = pd.DataFrame()\n",
    "\n",
    "for p_index, pID in enumerate(df_LikertPivot.ParticipantPublicID.unique()):\n",
    "    tmp = df_LikertPivot[df_LikertPivot['ParticipantPublicID']==pID][['NumericResponse']]\n",
    "    tmp['ParticipantPublicID']=pID\n",
    "    tmp['likertName'] = df_LikertPivot[df_LikertPivot['ParticipantPublicID']==pID]['likertName']\n",
    "    # Need to add in comparison numeric answers....\n",
    "    tmp = tmp.append(df_CompPivot[df_CompPivot['ParticipantPublicID']==pID])\n",
    "#     print(tmp)\n",
    "    tmp = tmp.dropna()\n",
    "    \n",
    "    # need to first check if all the same values, as this breaks zscore\n",
    "    if (len(np.unique(tmp.NumericResponse))==1):\n",
    "        print(pID)\n",
    "        tmp = tmp.rename(columns={'NumericResponse': 'Z_Scores', 'Question':'likertName'})\n",
    "        tmp['likertName'] = tmp['likertName'].astype(str)+\"_Z\"\n",
    "        tmp['Z_Scores'] = 0\n",
    "#         print(\"All same\")\n",
    "#         print(tmp)\n",
    "        newDF = newDF.append(tmp)\n",
    "    else:\n",
    "#         print(pID)\n",
    "        tmp['Z_Scores'] = stats.zscore(tmp['NumericResponse'])\n",
    "        tmp['ParticipantPublicID']=pID\n",
    "        tmp['likertName'] = tmp['likertName'].astype(str)+\"_Z\"\n",
    "        tmp = tmp.reset_index()\n",
    "        tmp = tmp.drop('NumericResponse',axis=1)\n",
    "#         print(\"Varied\")\n",
    "#         print(tmp)\n",
    "        newDF = newDF.append(tmp)\n",
    "#     print(\"Stacked as we go\")\n",
    "#     print(newDF)\n",
    "# print(\"Final product\")\n",
    "print(newDF.columns.tolist())\n",
    "    # Once calculated, need to make little DF and stack them up.... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['charts_helpful_1_Z' 'scenarios_helpful_1_Z' 'blurring_helpful_1_Z'\n",
      " 'info_sufficient_1_Z' 'charts_helpful_2_Z' 'scenarios_helpful_2_Z'\n",
      " 'blurring_helpful_2_Z' 'info_sufficient_2_Z' '17.0_Z' '18.0_Z' '19.0_Z'\n",
      " '20.0_Z' 'irrelevant_distracting_1_Z' 'irrelevant_distracting_2_Z']\n",
      "     index       ParticipantPublicID             likertName  Z_Scores\n",
      "0  75560.0  5ed57ec8141d24118731f1bc  scenarios_helpful_1_Z -0.904534\n",
      "1  75565.0  5ed57ec8141d24118731f1bc   blurring_helpful_1_Z -0.904534\n",
      "2  75570.0  5ed57ec8141d24118731f1bc    info_sufficient_1_Z  0.603023\n",
      "3  75635.0  5ed57ec8141d24118731f1bc  scenarios_helpful_2_Z  0.603023\n",
      "4  75640.0  5ed57ec8141d24118731f1bc   blurring_helpful_2_Z  0.603023\n",
      "5  75645.0  5ed57ec8141d24118731f1bc    info_sufficient_2_Z  0.603023\n",
      "6  75662.0  5ed57ec8141d24118731f1bc                 17.0_Z  0.603023\n",
      "7  75700.0  5ed57ec8141d24118731f1bc                 18.0_Z  0.603023\n",
      "8  75738.0  5ed57ec8141d24118731f1bc                 19.0_Z  0.603023\n",
      "9  75776.0  5ed57ec8141d24118731f1bc                 20.0_Z -2.412091\n"
     ]
    }
   ],
   "source": [
    "print(newDF.likertName.unique())\n",
    "print(newDF[newDF['ParticipantPublicID']==pID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.0_Z                   0.603023\n",
      "18.0_Z                   0.603023\n",
      "19.0_Z                   0.603023\n",
      "20.0_Z                  -2.412091\n",
      "blurring_helpful_1_Z    -0.904534\n",
      "blurring_helpful_2_Z     0.603023\n",
      "info_sufficient_1_Z      0.603023\n",
      "info_sufficient_2_Z      0.603023\n",
      "scenarios_helpful_1_Z   -0.904534\n",
      "scenarios_helpful_2_Z    0.603023\n",
      "Name: 5ed57ec8141d24118731f1bc, dtype: float64\n",
      "17.0_Z                   0.603023\n",
      "18.0_Z                   0.603023\n",
      "19.0_Z                   0.603023\n",
      "20.0_Z                  -2.412091\n",
      "blurring_helpful_1_Z    -0.904534\n",
      "blurring_helpful_2_Z     0.603023\n",
      "info_sufficient_1_Z      0.603023\n",
      "info_sufficient_2_Z      0.603023\n",
      "scenarios_helpful_1_Z   -0.904534\n",
      "scenarios_helpful_2_Z    0.603023\n",
      "Name: 5ed57ec8141d24118731f1bc, dtype: float64\n",
      "          ParticipantPublicID  17.0_Z  18.0_Z  19.0_Z  20.0_Z  \\\n",
      "231  5ed57ec8141d24118731f1bc     NaN     NaN     NaN     NaN   \n",
      "\n",
      "     blurring_helpful_1_Z  blurring_helpful_2_Z  info_sufficient_1_Z  \\\n",
      "231                   NaN                   NaN                  NaN   \n",
      "\n",
      "     info_sufficient_2_Z  scenarios_helpful_1_Z  scenarios_helpful_2_Z  \n",
      "231                  NaN                    NaN                    NaN  \n"
     ]
    }
   ],
   "source": [
    "# instead of below, set both indices to pID and then sort on index, concat, and reset index\n",
    "testDF = likertSlim.copy()\n",
    "\n",
    "tmp2 =  newDF[['Z_Scores', 'likertName','ParticipantPublicID']].pivot(index='ParticipantPublicID', columns=['likertName'], values='Z_Scores').rename_axis(None, axis=1)\n",
    "print(tmp2.loc[pID][['17.0_Z', '18.0_Z', '19.0_Z', '20.0_Z', \\\n",
    "                   'blurring_helpful_1_Z', 'blurring_helpful_2_Z', 'info_sufficient_1_Z', \\\n",
    "                   'info_sufficient_2_Z', 'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z']])\n",
    "\n",
    "# print(tmp2.iloc[:5])\n",
    "tmp2.sort_index()\n",
    "print(tmp2.loc[pID][['17.0_Z', '18.0_Z', '19.0_Z', '20.0_Z', \\\n",
    "                   'blurring_helpful_1_Z', 'blurring_helpful_2_Z', 'info_sufficient_1_Z', \\\n",
    "                   'info_sufficient_2_Z', 'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z']])\n",
    "testDF.set_index('ParticipantPublicID').sort_index()\n",
    "\n",
    "testDF = pd.concat([testDF,tmp2], axis=1)\n",
    "\n",
    "testDF = testDF.reset_index()\n",
    "print(testDF[testDF['ParticipantPublicID']==pID][['ParticipantPublicID', '17.0_Z', '18.0_Z', '19.0_Z', '20.0_Z', \\\n",
    "                   'blurring_helpful_1_Z', 'blurring_helpful_2_Z', 'info_sufficient_1_Z', \\\n",
    "                   'info_sufficient_2_Z', 'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ParticipantPublicID    17.0_Z    18.0_Z    19.0_Z    20.0_Z  \\\n",
      "231  5ed57ec8141d24118731f1bc  0.603023  0.603023  0.603023 -2.412091   \n",
      "\n",
      "     blurring_helpful_1_Z  blurring_helpful_2_Z  info_sufficient_1_Z  \\\n",
      "231             -0.904534              0.603023             0.603023   \n",
      "\n",
      "     info_sufficient_2_Z  scenarios_helpful_1_Z  scenarios_helpful_2_Z  \\\n",
      "231             0.603023              -0.904534               0.603023   \n",
      "\n",
      "     irrelevant_distracting_1_Z  irrelevant_distracting_2_Z  \\\n",
      "231                         NaN                         NaN   \n",
      "\n",
      "     charts_helpful_1_Z  charts_helpful_2_Z  \n",
      "231                 NaN                 NaN  \n",
      "232\n",
      "          ParticipantPublicID    17.0_Z    18.0_Z    19.0_Z    20.0_Z  \\\n",
      "0    5fc94c64c8a3e03ded162dd4  0.000000 -1.224745  0.000000 -1.224745   \n",
      "1    5f4557043bf01d125f02f01a  0.654654  0.654654  0.654654 -1.527525   \n",
      "2    5ed7f3404ea9bd2e0ad02df6 -0.095783  0.862044  0.862044 -0.095783   \n",
      "3    5e4ab1b4ca765d000edebd15  0.862840  0.862840  1.659308  0.862840   \n",
      "4    5f073f7fe606560bfafc28c1  1.069045  1.069045  1.069045  1.069045   \n",
      "..                        ...       ...       ...       ...       ...   \n",
      "227  5c35655f87b777000170d85a  0.685994  0.685994  0.685994  0.685994   \n",
      "228  5ede3eee12a7d606d1fd7686  0.272727  1.181818  1.181818  1.181818   \n",
      "229  5afdb5993eb22c00019bb339  0.000000  0.000000  0.000000  0.000000   \n",
      "230  5e67bcf03f8a34063871ba27 -0.654654 -0.654654 -0.654654 -0.654654   \n",
      "231  5ed57ec8141d24118731f1bc  0.603023  0.603023  0.603023 -2.412091   \n",
      "\n",
      "     blurring_helpful_1_Z  blurring_helpful_2_Z  info_sufficient_1_Z  \\\n",
      "0                1.224745              1.224745            -1.224745   \n",
      "1                     NaN                   NaN             0.654654   \n",
      "2               -2.011435              0.862044            -1.053609   \n",
      "3               -1.526564             -1.526564            -0.730096   \n",
      "4               -0.534522              0.267261            -1.336306   \n",
      "..                    ...                   ...                  ...   \n",
      "227             -1.886484             -1.886484             0.685994   \n",
      "228                   NaN                   NaN             0.272727   \n",
      "229              0.000000              0.000000             0.000000   \n",
      "230                   NaN                   NaN             1.527525   \n",
      "231             -0.904534              0.603023             0.603023   \n",
      "\n",
      "     info_sufficient_2_Z  scenarios_helpful_1_Z  scenarios_helpful_2_Z  \\\n",
      "0              -1.224745               1.224745               1.224745   \n",
      "1               0.654654                    NaN                    NaN   \n",
      "2               0.862044              -1.053609               0.862044   \n",
      "3               0.066372              -0.730096               0.862840   \n",
      "4              -1.336306               1.069045              -0.534522   \n",
      "..                   ...                    ...                    ...   \n",
      "227            -0.171499               0.685994              -0.171499   \n",
      "228            -1.545455                    NaN                    NaN   \n",
      "229             0.000000               0.000000               0.000000   \n",
      "230            -0.654654                    NaN                    NaN   \n",
      "231             0.603023              -0.904534               0.603023   \n",
      "\n",
      "     irrelevant_distracting_1_Z  irrelevant_distracting_2_Z  \\\n",
      "0                           NaN                         NaN   \n",
      "1                     -1.527525                   -1.527525   \n",
      "2                           NaN                         NaN   \n",
      "3                           NaN                         NaN   \n",
      "4                           NaN                         NaN   \n",
      "..                          ...                         ...   \n",
      "227                         NaN                         NaN   \n",
      "228                    0.272727                   -0.636364   \n",
      "229                         NaN                         NaN   \n",
      "230                   -0.654654                   -0.654654   \n",
      "231                         NaN                         NaN   \n",
      "\n",
      "     charts_helpful_1_Z  charts_helpful_2_Z  \n",
      "0              0.000000            0.000000  \n",
      "1              0.654654            0.654654  \n",
      "2                   NaN                 NaN  \n",
      "3              0.066372           -0.730096  \n",
      "4             -1.336306           -0.534522  \n",
      "..                  ...                 ...  \n",
      "227                 NaN                 NaN  \n",
      "228           -0.636364           -1.545455  \n",
      "229            0.000000            0.000000  \n",
      "230            1.527525            1.527525  \n",
      "231                 NaN                 NaN  \n",
      "\n",
      "[232 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############STOPPED HERE####### \n",
    "\n",
    "# Need to get tmp into pivoted format and plop onto end of SlimDF!!\n",
    "testDF = likertSlim.copy()\n",
    "\n",
    "tmp2 =  newDF[['Z_Scores', 'likertName','ParticipantPublicID']].pivot(index='ParticipantPublicID', columns=['likertName'], values='Z_Scores')\n",
    "# tmp2.set_index('ParticipantPublicID')\n",
    "tmp2 = tmp2.reset_index()\n",
    "# print(idx)\n",
    "# idx.rename('ParticipantPublicID')\n",
    "# tmp2 =  df_LikertPivot.groupby('ParticipantPublicID').sum().stack()\n",
    "# print(tmp2.head(5))\n",
    "# print(likertSlim.columns.tolist())\n",
    "# print(tmp2.columns.tolist())\n",
    "testDF = pd.merge(testDF,tmp2[['ParticipantPublicID', '17.0_Z', '18.0_Z', '19.0_Z', '20.0_Z', \\\n",
    "                   'blurring_helpful_1_Z', 'blurring_helpful_2_Z', 'info_sufficient_1_Z', \\\n",
    "                   'info_sufficient_2_Z', 'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z',\n",
    "                              'irrelevant_distracting_1_Z', 'irrelevant_distracting_2_Z', \\\n",
    "                              'charts_helpful_1_Z', 'charts_helpful_2_Z']], \\\n",
    "                    on='ParticipantPublicID',how=\"outer\")\n",
    "\n",
    "print(testDF[testDF['ParticipantPublicID']==pID][['ParticipantPublicID', '17.0_Z', '18.0_Z', '19.0_Z', '20.0_Z', \\\n",
    "                   'blurring_helpful_1_Z', 'blurring_helpful_2_Z', 'info_sufficient_1_Z', \\\n",
    "                   'info_sufficient_2_Z', 'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z',\n",
    "                              'irrelevant_distracting_1_Z', 'irrelevant_distracting_2_Z', \\\n",
    "                              'charts_helpful_1_Z', 'charts_helpful_2_Z']])\n",
    "print(len(testDF))\n",
    "print(testDF[['ParticipantPublicID', '17.0_Z', '18.0_Z', '19.0_Z', '20.0_Z', \\\n",
    "                   'blurring_helpful_1_Z', 'blurring_helpful_2_Z', 'info_sufficient_1_Z', \\\n",
    "                   'info_sufficient_2_Z', 'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z',\n",
    "                              'irrelevant_distracting_1_Z', 'irrelevant_distracting_2_Z', \\\n",
    "                              'charts_helpful_1_Z', 'charts_helpful_2_Z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.22474487         nan -2.0114352  -1.52656362 -0.53452248  1.03923048\n",
      " -1.45174713 -1.06904497 -1.3764944   0.         -2.         -1.22474487\n",
      " -0.4472136  -0.77204865  0.5        -0.79240582 -1.83711731  0.18569534\n",
      " -1.57798601 -0.84515425  0.65465367 -1.43165827  1.28571429 -2.42487113\n",
      " -1.33484762 -0.30151134 -1.69030851 -0.35355339 -1.02513857 -1.22474487\n",
      " -1.79231397 -0.30151134 -0.4472136   0.91132238  0.84515425 -1.09321633\n",
      "  0.69652603 -0.09578263 -1.82574186 -1.35680105  0.10599979 -0.20851441\n",
      " -1.19316609  0.91132238 -2.0195672  -1.33978769  0.43643578 -0.5\n",
      " -1.06904497 -0.08192319  0.77777778 -1.18321596 -1.11803399  1.76930347\n",
      " -1.62221421  0.14285714 -0.58834841 -1.29099445 -1.          1.6583124\n",
      " -1.69245584  0.42008403 -1.60591014  0.89442719 -0.82055272 -1.85996222\n",
      "  0.96225045 -1.62746694  0.5488213  -2.0302589  -0.39223227  0.20412415\n",
      " -0.77777778 -0.90535746 -1.62221421 -1.04418513 -0.81649658  0.35355339\n",
      " -2.04264872  0.62017367 -1.90443316 -0.54232614 -0.46852129  1.43165827\n",
      " -1.03209369  2.0302589  -1.57142857 -0.30151134 -1.29354835  0.13018891\n",
      " -1.62697843  0.30151134 -1.50755672 -0.89442719 -1.72038703  0.33333333\n",
      "  0.78086881 -0.33333333 -0.74278135 -1.88648444 -0.90453403]\n",
      "[ 1.22474487         nan  0.86204366 -1.52656362  0.26726124  1.03923048\n",
      " -1.45174713 -1.06904497 -0.22941573  0.         -0.75       -1.22474487\n",
      " -1.73205081 -1.34164079 -1.61428353  0.5         0.08804509 -1.83711731\n",
      " -0.92847669 -1.57798601 -0.84515425  0.65465367  0.25264558  1.28571429\n",
      "  0.34641016  0.95346259 -0.30151134 -1.69030851  0.81649658  0.70710678\n",
      " -0.30151134 -1.22474487 -1.79231397 -1.20604538 -0.4472136  -0.65094455\n",
      " -2.44948974  0.84515425 -1.09321633 -1.29354835 -1.05360891 -1.82574186\n",
      " -1.35680105  1.16599767 -1.4596009  -1.19316609 -0.65094455 -2.0195672\n",
      " -1.33978769  0.43643578 -0.5         1.60356745 -0.90115511  0.77777778\n",
      "  0.84515425 -1.11803399  1.03209369 -1.62221421  0.14285714 -1.56892908\n",
      " -1.06904497 -0.54433105 -1.         -0.60302269 -0.13018891  0.42008403\n",
      " -0.6882472   0.89442719 -0.82055272 -1.85996222  0.96225045 -0.92998111\n",
      "  0.5488213  -0.46852129 -0.39223227 -0.4472136   1.22474487 -0.77777778\n",
      " -0.90535746  1.29777137 -1.04418513 -0.81649658 -0.70710678 -2.04264872\n",
      "  0.62017367 -1.90443316 -0.54232614 -1.0947975  -0.29488391  0.46852129\n",
      " -1.57142857 -0.30151134 -0.29851116  0.13018891  0.30151134  0.30151134\n",
      " -0.34641016 -2.23606798  0.33333333  0.78086881  1.33333333  1.11417203\n",
      " -1.88648444  0.60302269]\n",
      "[-1.22474487  0.65465367 -1.05360891 -0.73009564 -1.33630621  0.08804509\n",
      " -1.73205081 -1.45174713 -0.39223227 -0.22941573 -0.5        -1.06904497\n",
      " -1.11803399 -2.          0.06608186  1.2493901  -0.75       -1.22474487\n",
      " -1.56892908 -1.11417203  1.3764944  -1.16599767  1.11417203 -1.46385011\n",
      " -0.65465367 -1.86052102  0.         -0.65465367  0.4472136   0.07018624\n",
      " -0.84515425  0.22941573  0.5        -1.67285672  0.20412415  0.18569534\n",
      "  0.69431384 -0.84515425  0.65465367 -1.43165827 -1.57142857 -1.03923048\n",
      " -1.33484762  0.90453403  1.28571429  1.05360891 -0.18569534 -1.58113883\n",
      " -0.79240582  0.26726124 -1.61538462 -0.4472136  -0.35355339 -1.02513857\n",
      " -0.4888129  -1.20604538 -0.38411064 -0.42008403 -1.60356745 -0.4472136\n",
      "  0.91132238 -1.18321596  0.5         1.54545455 -1.06904497 -0.33333333\n",
      " -0.17149859  0.46852129 -0.29851116  0.86204366 -1.29099445 -0.60302269\n",
      " -0.95399809 -1.4596009  -0.48795004  1.02454353 -1.19316609 -2.21321149\n",
      " -0.55079106 -0.43643578 -0.54232614 -0.43643578 -1.74574312 -0.5\n",
      "  1.75       -1.72038703  0.77777778 -1.08347268  0.81649658 -1.16666667\n",
      "  0.74535599 -0.12038585  1.09321633  0.84515425 -0.74535599 -1.\n",
      "  0.29488391 -0.64888568  0.14285714  0.39223227 -1.66447944 -1.4969104\n",
      " -0.26726124 -1.25723711 -1.35680105 -0.13018891 -1.26025208 -0.6882472\n",
      " -1.18181818  1.34164079  0.89442719 -1.57798601  0.23249528 -2.11695099\n",
      " -0.92998111 -2.08552094  0.33333333 -0.46852129 -1.37281295  1.22474487\n",
      " -0.77777778 -0.36214298 -1.62221421 -0.81649658 -0.89625816 -1.04418513\n",
      " -0.78113347 -0.70710678  1.29986737 -2.23606798 -0.58834841  0.62017367\n",
      " -2.09090909 -0.90453403  0.21160368 -1.62697843 -0.14285714 -0.20412415\n",
      " -1.37281295  1.67125804  2.65495395 -1.0947975  -0.29488391  0.46852129\n",
      " -0.39223227 -0.96076892 -1.09321633 -2.11057941 -1.29354835  0.13018891\n",
      " -1.44115338  0.91766294 -0.86204366 -1.45260037  0.29488391  1.11803399\n",
      "  0.30151134 -1.50755672 -0.89442719  0.09578263 -0.90115511 -3.\n",
      " -0.15617376 -0.81649658  1.33333333  0.18569534 -2.5819889   0.68599434\n",
      "  0.27272727  1.52752523  0.60302269]\n",
      "[-1.22474487  0.65465367  0.86204366  0.06637233 -1.33630621  0.08804509\n",
      " -1.73205081 -0.69431384 -0.39223227 -1.3764944  -1.75       -1.06904497\n",
      " -0.22941573 -1.11803399 -0.33333333 -1.25555534  0.46852129  0.5\n",
      "  0.81649658 -0.58834841  0.74278135  0.22941573 -0.10599979  1.11417203\n",
      " -1.46385011 -0.65465367 -0.62017367  0.         -0.65465367 -0.4472136\n",
      " -0.77204865 -1.69030851  0.22941573  0.5        -0.79240582  0.20412415\n",
      " -0.92847669  0.69431384 -0.84515425  0.65465367  0.25264558 -0.14285714\n",
      " -1.03923048  0.95346259 -0.30151134 -0.14285714  0.09578263 -0.18569534\n",
      " -1.58113883  0.968496    0.26726124 -0.84615385 -1.56892908 -0.84515425\n",
      " -1.22474487  0.70710678 -0.30151134  0.81468817 -1.20604538  0.89625816\n",
      " -1.12022407 -0.26726124 -0.4472136   0.91132238 -1.18321596  0.63636364\n",
      "  0.77777778 -1.         -0.17149859 -1.09321633  0.69652603 -1.05360891\n",
      " -1.29099445  0.15075567  0.10599979 -1.4596009  -0.48795004  0.23643312\n",
      " -0.3509312  -0.65094455  0.18359702 -1.52752523  0.54232614 -0.43643578\n",
      " -0.55167728 -1.74574312  2.         -1.06904497  0.73730873 -1.08347268\n",
      " -0.5        -1.16666667  0.74535599 -1.32424438  1.09321633 -1.18321596\n",
      " -0.5        -0.74535599 -1.17953565  0.32444284  1.57142857  0.39223227\n",
      " -2.21321149  2.23606798 -0.38411064 -1.4969104   1.06904497  0.69230769\n",
      " -0.3592106   0.46852129  0.81649658  1.         -1.35680105  1.43207802\n",
      " -2.94058818 -1.60591014 -1.18181818  0.43643578 -1.78885438 -1.57798601\n",
      "  0.23249528  0.19245009 -0.23249528 -2.08552094  0.33333333  1.2493901\n",
      " -0.46852129 -1.37281295  0.20412415 -0.77777778  0.72428597 -1.62221421\n",
      " -0.81649658 -0.89625816 -0.08032193 -0.78113347  0.35355339  1.29986737\n",
      "  1.37281295  0.62017367  0.60302269  0.21160368 -0.54232614 -1.57142857\n",
      "  0.58834841 -2.04264872 -1.0947975  -1.03209369  0.64051262 -0.14285714\n",
      " -0.30151134 -0.29851116  0.13018891 -0.64051262  0.91766294 -0.86204366\n",
      " -0.25264558 -0.06917145  0.29488391  0.30151134 -0.60302269 -0.89442719\n",
      " -0.08192319  0.78086881  0.54433105 -1.52752523  0.18569534 -0.65465367\n",
      " -0.17149859 -1.54545455]\n",
      "[ 1.22474487         nan -1.05360891 -0.73009564  1.06904497  1.03923048\n",
      "  0.82055272  0.58834841 -0.22941573 -0.5         0.26726124 -1.11803399\n",
      " -0.33333333  0.72690046 -1.09321633  1.75        0.81649658  0.39223227\n",
      " -0.18569534  0.22941573 -0.10599979 -1.67125804  0.48795004 -0.65465367\n",
      "  0.         -1.34164079  0.07018624  0.5        -0.79240582  0.20412415\n",
      " -0.92847669 -0.82055272  1.18321596 -1.52752523  0.25264558 -0.14285714\n",
      "  0.34641016 -1.33484762 -0.30151134 -0.14285714  0.09578263  1.67125804\n",
      "  0.08804509  0.26726124 -0.84615385  0.84515425  0.70710678 -1.02513857\n",
      "  0.16293763  0.60302269 -0.38411064  0.98019606  2.23606798 -0.65094455\n",
      "  0.84515425  0.46852129 -1.29354835  0.86204366 -1.29099445  0.90453403\n",
      " -2.01399597 -0.20851441 -0.3509312  -0.65094455  0.91798509 -0.43643578\n",
      " -1.62697843 -2.61861468  1.02454353  0.43643578  2.          0.5\n",
      " -0.90115511  0.77777778  1.32424438 -0.5        -0.33333333 -0.74535599\n",
      "  0.12038585  1.08347268 -1.18321596  1.03209369 -0.64888568 -1.28571429\n",
      " -1.56892908  0.91132238  0.53452248 -0.26726124 -1.22474487 -1.\n",
      " -0.60302269 -0.13018891  0.42008403  1.14707867 -1.18181818 -0.4472136\n",
      " -0.06311944 -1.16247639  0.19245009 -1.62746694  0.5488213  -0.46852129\n",
      " -0.39223227  1.34164079  0.20412415 -0.77777778 -0.90535746  1.29099445\n",
      "  1.09321633  0.32444284 -0.08032193 -0.78113347  1.22474487  1.41421356\n",
      "  0.18569534  0.74535599  0.62017367 -0.90453403  0.21160368 -0.54232614\n",
      " -2.23606798 -0.14285714 -0.20412415  0.58834841  1.43165827  1.17953565\n",
      " -0.30151134 -0.29851116  0.13018891 -0.64051262 -1.0947975  -0.76088591\n",
      "  1.11803399  0.30151134  0.30151134 -0.34641016  0.4472136   0.968496\n",
      "  0.33333333  0.78086881  0.18569534  0.68599434]\n",
      "[ 1.22474487         nan  0.86204366  0.86284031 -0.53452248 -0.34641016\n",
      "  0.82055272 -1.37281295 -0.22941573 -0.5         0.26726124 -1.3764944\n",
      "  0.          1.33333333 -1.25555534 -0.31234752 -0.75       -1.22474487\n",
      "  0.39223227  0.74278135 -0.91766294 -0.10599979  0.18569534  0.48795004\n",
      "  0.43643578  1.73205081  0.4472136   0.07018624  0.5         0.968496\n",
      "  0.20412415 -0.92847669  0.69431384 -0.84515425  0.65465367 -1.43165827\n",
      " -0.14285714  0.34641016  0.95346259 -0.30151134 -1.57142857  1.05360891\n",
      " -0.18569534  0.08804509 -2.40535118  0.69230769  0.84515425  0.81649658\n",
      " -0.35355339 -0.30151134 -1.14056344 -0.30151134  0.89625816 -1.12022407\n",
      " -0.4472136  -0.65094455 -0.16903085  0.46852129  0.69652603  1.29099445\n",
      " -1.35680105  0.10599979  1.04257207 -1.19316609 -0.65094455  0.91798509\n",
      " -0.43643578 -0.54232614 -1.33978769  0.43643578 -0.5         0.26726124\n",
      "  0.73730873  0.77777778  1.32424438 -0.33333333  0.74535599  0.12038585\n",
      " -0.12038585 -1.18321596 -1.11803399 -0.44232587  0.32444284 -1.28571429\n",
      " -0.58834841  0.53452248  1.06904497 -0.07692308  0.81649658 -1.\n",
      " -0.60302269 -0.13018891  0.42008403  1.14707867 -1.18181818  1.52752523\n",
      "  0.89442719 -0.06311944  0.23249528  0.96225045  1.16247639  0.5488213\n",
      " -0.46852129 -0.39223227  1.34164079  0.20412415 -0.77777778 -0.90535746\n",
      " -1.29099445  1.09321633  0.32444284 -1.04418513 -0.78113347  1.22474487\n",
      " -1.76776695  0.18569534  0.62017367  0.63636364  0.60302269  0.21160368\n",
      " -0.14285714 -0.20412415  0.58834841 -0.25264558  1.17953565 -1.09321633\n",
      "  1.50755672 -0.29851116  0.13018891  0.96076892  0.58950634  1.31425748\n",
      "  0.54232614  0.30151134  0.30151134  1.03923048  0.4472136  -0.86204366\n",
      "  0.33333333  0.78086881 -0.33333333  1.11417203 -0.17149859]\n",
      "[        nan -1.52752523  0.968496   -0.39223227 -0.22941573 -0.5\n",
      " -0.33333333 -0.59473674 -1.87408514 -0.58834841 -1.11417203  0.22941573\n",
      "  0.95399809 -1.67125804 -0.48795004  0.43643578  0.62017367 -2.23606798\n",
      " -0.65465367  0.84515425  0.22941573 -1.57142857 -1.81986994 -0.18569534\n",
      "  0.65465367  0.         -1.67285672  0.26726124 -0.07692308 -0.4472136\n",
      "  0.39223227  0.89625816 -1.12022407 -0.26726124 -0.81649658 -2.\n",
      " -1.18181818  0.77777778 -0.17149859  1.46385011 -2.1278981  -0.43643578\n",
      " -0.54232614 -0.43643578 -0.75        0.12038585 -0.5         0.81649658\n",
      " -0.33333333 -1.22474487 -1.08347268 -1.32424438 -2.0302589  -1.11803399\n",
      " -1.75       -0.74535599  1.          2.         -1.66447944  0.54433105\n",
      " -1.60356745 -0.84615385 -1.25723711  0.46852129  0.63636364 -1.74574312\n",
      "  0.33333333 -1.09321633 -0.89625816  0.74535599 -0.78113347 -1.56892908\n",
      " -2.41209076 -0.14285714 -1.37281295 -0.18569534 -2.35339362 -0.96076892\n",
      " -0.64051262  0.09578263  1.43165827 -0.76088591 -1.17953565 -0.79240582\n",
      " -0.86204366 -1.57142857 -1.4969104  -0.43643578  0.27272727]\n",
      "[        nan -1.52752523  0.968496   -1.37281295 -0.22941573  0.75\n",
      " -0.33333333 -1.25555534 -1.09321633 -1.56892908 -1.11417203 -2.0647416\n",
      " -0.10599979  0.18569534 -0.48795004  0.43643578  0.62017367  0.\n",
      " -0.65465367  0.84515425  0.22941573 -0.14285714 -1.81986994 -2.04264872\n",
      "  0.65465367 -1.67285672 -1.06904497 -0.07692308 -1.34164079  0.39223227\n",
      "  0.89625816 -1.12022407 -0.26726124 -0.81649658 -2.         -1.18181818\n",
      "  0.26726124 -0.33333333 -1.         -1.02899151  1.46385011  0.23643312\n",
      " -0.43643578 -0.54232614 -0.75        0.12038585 -0.5         0.81649658\n",
      " -1.16666667  0.74535599 -1.08347268 -1.32424438 -0.46852129 -1.11803399\n",
      " -1.75       -0.74535599 -0.38411064  0.54433105 -1.60356745 -0.84615385\n",
      " -1.25723711 -2.65495395  0.63636364 -0.65465367 -1.22474487  0.33333333\n",
      " -0.89625816 -0.78113347  0.60302269 -1.57142857 -0.39223227 -0.18569534\n",
      " -1.87408514 -1.37281295 -0.96076892 -0.64051262 -0.86204366  1.43165827\n",
      "  0.62254302 -1.17953565 -0.79240582 -0.43643578 -0.63636364]\n",
      "[ 0.          0.65465367         nan  0.06637233 -1.33630621  0.08804509\n",
      " -0.34641016  0.06311944 -1.86052102 -0.65465367 -0.4472136   0.91242113\n",
      " -0.91766294 -0.92847669 -1.57798601  0.16903085  0.34641016 -1.33484762\n",
      " -1.50755672 -1.52752523  1.34164079 -0.58834841  0.70710678 -1.02513857\n",
      "  0.81468817  0.60302269  1.06904497 -1.83711731 -0.4472136  -2.21321149\n",
      "  0.84515425  0.5         0.63636364  0.26726124 -0.33333333 -1.\n",
      " -0.17149859  1.04257207 -1.46385011 -1.33978769  0.49130368 -0.65094455\n",
      "  0.18359702 -0.46852129 -0.33333333  0.84515425  0.75        0.74535599\n",
      "  0.32444284 -0.65094455  0.53452248 -0.38411064 -0.81649658  0.53881591\n",
      "  0.46852129 -0.13018891  0.42008403 -0.6882472   0.81649658 -0.4472136\n",
      " -0.06311944  0.23249528 -1.34715063  0.46499055  0.5488213  -0.74535599\n",
      "  0.33333333 -1.09321633 -0.90535746  0.32444284 -0.81649658  0.38411064\n",
      " -1.04418513  0.35355339  0.18569534 -0.18569534  0.58834841 -0.96076892\n",
      " -0.30151134  0.13018891  0.91766294 -0.86204366  1.03209369  0.30151134\n",
      "  0.30151134  0.4472136  -0.79240582  0.78086881 -0.14285714 -0.43643578\n",
      " -0.63636364  1.52752523]\n",
      "[ 0.          0.65465367         nan -0.73009564 -0.53452248  0.08804509\n",
      " -0.34641016  0.82055272  0.62017367 -0.65465367  0.4472136   1.75465602\n",
      " -1.69030851 -0.91766294 -0.92847669  0.69431384 -0.84515425  0.34641016\n",
      "  0.95346259 -1.50755672 -1.52752523  1.34164079 -0.58834841  1.76776695\n",
      " -0.30151134  1.22474487  0.16293763 -1.20604538  1.06904497 -0.81649658\n",
      "  2.23606798 -0.65094455  0.84515425  0.5        -1.18181818  0.26726124\n",
      "  0.77777778 -1.         -0.17149859  1.04257207 -1.46385011  0.23643312\n",
      "  0.49130368  0.91132238  0.91798509 -0.46852129 -0.33333333 -1.18321596\n",
      "  0.75        0.74535599 -0.64888568  0.53452248  0.89625816 -0.81649658\n",
      "  0.53881591  0.46852129 -1.69245584  0.42008403  0.22941573  0.81649658\n",
      " -0.4472136  -0.4472136   0.69431384  0.23249528 -1.34715063  0.46499055\n",
      "  0.5488213   0.33333333 -0.31234752 -0.90535746  0.32444284 -0.89625816\n",
      "  0.88354126  1.41421356  0.18569534 -0.18569534  0.46852129  0.58834841\n",
      " -0.96076892  1.50755672  0.13018891  0.91766294 -0.86204366  1.03209369\n",
      " -3.31662479  0.30151134  1.03923048  1.78885438 -0.79240582 -0.15617376\n",
      " -0.14285714 -1.52752523 -1.54545455  1.52752523]\n"
     ]
    }
   ],
   "source": [
    "# print(testDF.columns.tolist())\n",
    "print(testDF.blurring_helpful_1_Z.unique())\n",
    "print(testDF.blurring_helpful_2_Z.unique())\n",
    "print(testDF.info_sufficient_1_Z.unique())\n",
    "print(testDF.info_sufficient_2_Z.unique())\n",
    "print(testDF.scenarios_helpful_1_Z.unique())\n",
    "print(testDF.scenarios_helpful_2_Z.unique())\n",
    "print(testDF.irrelevant_distracting_1_Z.unique())\n",
    "print(testDF.irrelevant_distracting_2_Z.unique())\n",
    "print(testDF.charts_helpful_1_Z.unique())\n",
    "print(testDF.charts_helpful_2_Z.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "likertSlim = testDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Make DF for Performance on comparisons\n",
    "# df_CompPivot = tmp_taskDF.query('AgentNum==3 & (Question!=0 | CompConf_Num!=0)')[['Response','Correct','Question', \\\n",
    "#                                                               'ParticipantPublicID', 'CompConf_Num']]\n",
    "# thisDF = slimDF.copy()\n",
    "# df_CompPivot['Response'] = pd.Categorical(df_CompPivot.Response)\n",
    "# print(df_CompPivot.head(4))\n",
    "\n",
    "# #move confcatvar and compconf up one\n",
    "# df_CompPivot['Response'] = df_CompPivot['Response'].shift(-1)\n",
    "# df_CompPivot['CompConf_Num'] = df_CompPivot['CompConf_Num'].shift(-1)\n",
    "# # df_CompPivot['confCatVar'] = df_CompPivot['confCatVar'].shift(-1)\n",
    "# df_CompPivot = df_CompPivot.query('Question!=0').dropna().rename(columns={'Question': \"likertName\"}).drop(columns=['CompConf_Num','Correct'])\n",
    "# print(df_CompPivot.Response.unique())\n",
    "\n",
    "# codes = {'Not at All Confident':1,'Not Confident':2, \\\n",
    "#          'Neutral':3,'Somewhat Confident':4,'Completely Confident':5}\n",
    "# # Now use map on sub-df to swap negative q sentiments\n",
    "# df_CompPivot['NumericResponse'] = df_CompPivot['Response'].map(codes)\n",
    "# df_CompPivot.drop('Response', axis=1, inplace=True)\n",
    "# print(df_CompPivot.head(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Response  Correct  Question       ParticipantPublicID\n",
      "index                                                                 \n",
      "101        Agent Thompson      0.0      17.0  5fc94c64c8a3e03ded162dd4\n",
      "102    Somewhat Confident      0.0       0.0  5fc94c64c8a3e03ded162dd4\n",
      "107         Agent Jackson      1.0      18.0  5fc94c64c8a3e03ded162dd4\n",
      "108               Neutral      0.0       0.0  5fc94c64c8a3e03ded162dd4\n",
      "       Response  Correct  Question       ParticipantPublicID\n",
      "index                                                       \n",
      "101         4.0      0.0      17.0  5fc94c64c8a3e03ded162dd4\n",
      "107         3.0      1.0      18.0  5fc94c64c8a3e03ded162dd4\n",
      "122         4.0      0.0      19.0  5fc94c64c8a3e03ded162dd4\n",
      "141         3.0      0.0      20.0  5fc94c64c8a3e03ded162dd4\n",
      "        ParticipantPublicID  Question  Response  Correct\n",
      "0  55bac673fdf99b554657f2d6      17.0       4.0      1.0\n",
      "1  55bac673fdf99b554657f2d6      18.0       4.0      1.0\n",
      "2  55bac673fdf99b554657f2d6      19.0       4.0      1.0\n",
      "3  55bac673fdf99b554657f2d6      20.0       4.0      1.0\n",
      "         ParticipantPublicID  Question  Q17_Response  Q17_Correct\n",
      "0   55bac673fdf99b554657f2d6      17.0           4.0          1.0\n",
      "4   55cf7e8b34e906000ee56498      17.0           3.0          1.0\n",
      "8   56db8f127dcddf000dd592af      17.0           4.0          1.0\n",
      "12  572f1c1d3c27e7000f0b31aa      17.0           4.0          1.0\n",
      "[4. 3. 5. 2. 1.]\n",
      "         ParticipantPublicID  Question  Q18_Response  Q18_Correct\n",
      "1   55bac673fdf99b554657f2d6      18.0           4.0          1.0\n",
      "5   55cf7e8b34e906000ee56498      18.0           1.0          0.0\n",
      "9   56db8f127dcddf000dd592af      18.0           3.0          1.0\n",
      "13  572f1c1d3c27e7000f0b31aa      18.0           3.0          0.0\n",
      "[3. 4. 2. 5. 1.]\n",
      "         ParticipantPublicID  Question  Q19_Response  Q19_Correct\n",
      "2   55bac673fdf99b554657f2d6      19.0           4.0          1.0\n",
      "6   55cf7e8b34e906000ee56498      19.0           2.0          0.0\n",
      "10  56db8f127dcddf000dd592af      19.0           4.0          0.0\n",
      "14  572f1c1d3c27e7000f0b31aa      19.0           3.0          1.0\n",
      "[4. 5. 3. 2. 1.]\n",
      "         ParticipantPublicID  Question  Q20_Response  Q20_Correct\n",
      "3   55bac673fdf99b554657f2d6      20.0           4.0          1.0\n",
      "7   55cf7e8b34e906000ee56498      20.0           2.0          1.0\n",
      "11  56db8f127dcddf000dd592af      20.0           3.0          1.0\n",
      "15  572f1c1d3c27e7000f0b31aa      20.0           3.0          0.0\n",
      "Added to Slim:\n",
      "  ParticipantPrivateID difficulty        visuals   agents  QsTotal  QsCorrect  \\\n",
      "0            3109877.0  Difficult  Blur_Plus_Vis  300_700       20        5.0   \n",
      "1            3109883.0       Easy        Visuals   23_700       20        1.0   \n",
      "2            3109878.0       Easy        Blurred   700_23       20        5.0   \n",
      "3            3135747.0  Difficult  Blur_Plus_Vis  700_300       20        8.0   \n",
      "\n",
      "   Agent_QsTotal  Agent_QsCorrect  Agent_QsWO_GhostsTotal  \\\n",
      "0             16              4.0                      12   \n",
      "1             16              1.0                      12   \n",
      "2             16              5.0                      12   \n",
      "3             16              5.0                      12   \n",
      "\n",
      "   Agent_QsWO_GhostsCorrect  ...  irrelevant_distracting_1_Z  \\\n",
      "0                       2.0  ...                         NaN   \n",
      "1                       1.0  ...                   -1.527525   \n",
      "2                       3.0  ...                         NaN   \n",
      "3                       5.0  ...                         NaN   \n",
      "\n",
      "   irrelevant_distracting_2_Z  charts_helpful_1_Z  charts_helpful_2_Z  \\\n",
      "0                         NaN            0.000000            0.000000   \n",
      "1                   -1.527525            0.654654            0.654654   \n",
      "2                         NaN                 NaN                 NaN   \n",
      "3                         NaN            0.066372           -0.730096   \n",
      "\n",
      "   Q17_Response  Q17_Correct  Q18_Response  Q18_Correct  Q19_Response  \\\n",
      "0           4.0          0.0           3.0          1.0           4.0   \n",
      "1           4.0          0.0           4.0          0.0           4.0   \n",
      "2           3.0          0.0           4.0          0.0           4.0   \n",
      "3           4.0          1.0           4.0          1.0           5.0   \n",
      "\n",
      "   Q19_Correct  \n",
      "0          0.0  \n",
      "1          0.0  \n",
      "2          0.0  \n",
      "3          1.0  \n",
      "\n",
      "[4 rows x 154 columns]\n",
      "[3. 2. 4. 1. 5.]\n",
      "0      3.0\n",
      "1      4.0\n",
      "2      3.0\n",
      "3      4.0\n",
      "4      4.0\n",
      "      ... \n",
      "227    5.0\n",
      "228    5.0\n",
      "229    4.0\n",
      "230    3.0\n",
      "231    4.0\n",
      "Name: CompResponseMode, Length: 232, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "df_CompPivot = tmp_taskDF.query('AgentNum==3 & (Question!=0 | CompConf_Num!=0)')[['Response','Correct','Question', \\\n",
    "                                                              'ParticipantPublicID']]\n",
    "thisDF = likertSlim.copy()\n",
    "df_CompPivot['Response'] = pd.Categorical(df_CompPivot.Response)\n",
    "print(df_CompPivot.head(4))\n",
    "# df_pivot.groupby(['VisCond','Question']).plot(kind=\"bar\", title = str(\"Comparison Confidence\"))\n",
    "\n",
    "#move confcatvar and compconf up one\n",
    "df_CompPivot['Response'] = df_CompPivot['Response'].shift(-1)\n",
    "# df_CompPivot['CompConf_Num'] = df_CompPivot['CompConf_Num'].shift(-1)\n",
    "# df_CompPivot['confCatVar'] = df_CompPivot['confCatVar'].shift(-1)\n",
    "df_CompPivot = df_CompPivot.dropna()\n",
    "df_CompPivot = df_CompPivot.query('Question!=0').copy()\n",
    "\n",
    "# Can we map to numbers here?\n",
    "codes = {'Not at All Confident':1,'Not Confident':2, 'Neutral':3,'Somewhat Confident':4,'Completely Confident':5}\n",
    "# Now use map on sub-df to swap negative q sentiments\n",
    "df_CompPivot['Response'] = df_CompPivot['Response'].map(codes)\n",
    "\n",
    "\n",
    "print(df_CompPivot.head(4))\n",
    "tmp2 =  df_CompPivot.pivot(index='ParticipantPublicID', columns=['Question'])\n",
    "tmp3 = tmp2.stack().reset_index()\n",
    "print(tmp3.head(4))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tmp_17 = tmp3[tmp3['Question']==17.0]\n",
    "tmp_17.rename(columns = {'Response': 'Q17_Response', 'Correct': 'Q17_Correct'}, inplace = True)\n",
    "print(tmp_17.head(4))\n",
    "thisDF = pd.merge(thisDF,tmp_17[['Q17_Response','Q17_Correct','ParticipantPublicID']],on='ParticipantPublicID',how=\"left\")\n",
    "print(thisDF.Q17_Response.unique())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tmp_18 = tmp3[tmp3['Question']==18.0]\n",
    "tmp_18.rename(columns = {'Response': 'Q18_Response', 'Correct': 'Q18_Correct'}, inplace = True)\n",
    "print(tmp_18.head(4))\n",
    "thisDF = pd.merge(thisDF,tmp_18[['Q18_Response','Q18_Correct','ParticipantPublicID']],on='ParticipantPublicID',how=\"left\")\n",
    "print(thisDF.Q18_Response.unique())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tmp_19 = tmp3[tmp3['Question']==19.0]\n",
    "tmp_19.rename(columns = {'Response': 'Q19_Response', 'Correct': 'Q19_Correct'}, inplace = True)\n",
    "print(tmp_19.head(4))\n",
    "thisDF = pd.merge(thisDF,tmp_19[['Q19_Response','Q19_Correct','ParticipantPublicID']],on='ParticipantPublicID',how=\"left\")\n",
    "print(thisDF.Q19_Response.unique())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tmp_20 = tmp3[tmp3['Question']==20.0]\n",
    "tmp_20.rename(columns = {'Response': 'Q20_Response', 'Correct': 'Q20_Correct'}, inplace = True)\n",
    "print(tmp_20.head(4))\n",
    "\n",
    "print(\"Added to Slim:\")\n",
    "print(thisDF.head(4))\n",
    "thisDF = pd.merge(thisDF,tmp_20[['Q20_Response','Q20_Correct','ParticipantPublicID']],on='ParticipantPublicID',how=\"left\")\n",
    "print(thisDF.Q20_Response.unique())\n",
    "\n",
    "\n",
    "thisDF['CompCorrectSum'] = thisDF['Q17_Correct'] + thisDF['Q18_Correct'] + thisDF['Q19_Correct'] + thisDF['Q20_Correct']\n",
    "\n",
    "thisDF['CompResponseMode'] = thisDF[['Q17_Response','Q18_Response','Q19_Response','Q20_Response']].mode(axis=1)[0]\n",
    "print(thisDF['CompResponseMode'])\n",
    "\n",
    "likertSlim = pd.merge(likertSlim,thisDF[['Q17_Response','Q17_Correct','Q18_Response','Q18_Correct',\n",
    "                                 'Q19_Response','Q19_Correct','Q20_Response','Q20_Correct', 'CompCorrectSum',\n",
    "                                 'CompResponseMode','ParticipantPublicID']],on='ParticipantPublicID',how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ParticipantPrivateID', 'difficulty', 'visuals', 'agents', 'QsTotal', 'QsCorrect', 'Agent_QsTotal', 'Agent_QsCorrect', 'Agent_QsWO_GhostsTotal', 'Agent_QsWO_GhostsCorrect', 'Qs1_Correct', 'Qs2_Correct', 'QsPart_Total', 'predictionsCorrect', 'predictionsTotal', 'predictions1Correct', 'predictions2Correct', 'predictionsHalfTotal', 'regionsCorrect', 'regionsTotal', 'regions1Correct', 'regions2Correct', 'regionsHalfTotal', 'levelCorrect', 'levelTotal', 'level1Correct', 'level2Correct', 'levelHalfTotal', 'ghostsCorrect', 'ghostsTotal', 'ghosts1Correct', 'ghosts2Correct', 'ghostsHalfTotal', 'comparisonsCorrect', 'comparisonsTotal', 'timeTakenMain_All', 'timeTakenMain_AgentsOnly', 'timeTaken_Consent', 'timeTaken_Demographics', 'timeTaken_AI', 'timeTaken_Agent1', 'timeTaken_Agent2', 'timeTaken_Agent3', 'time_TOTAL', 'vidPlayed', 'avgVidPlays', 'ratioVidPlaysToAvg', 'ExperimentVersion_x', 'totPerc', 'agTotPerc', 'tot1Perc', 'tot2Perc', 'Agent_QsWO_GhostsPerc', 'predPerc', 'pred1Perc', 'pred2Perc', 'regPerc', 'reg1Perc', 'reg2Perc', 'lvlPerc', 'lvl1Perc', 'lvl2Perc', 'ghostPerc', 'ghost1Perc', 'ghost2Perc', 'compPerc', 'TreeNodeKey_x', 'age_info', 'age_info_text', 'age_info_quantised', 'gender_id', 'gender_id_text', 'gender_id_quantised', 'education_level', 'education_level_text', 'education_level_quantised', 'ExperimentVersion', 'ParticipantPublicID', 'ai_involvement_1', 'ai_involvement_2', 'ai_involvement_3', 'ai_involvement_4', 'ai_involvement_5', 'ai_involvement_6', 'ai_involvement_text', 'ai_involvement_other', 'ai_opinion', 'ai_opinion_quantised', 'AI_longForm', 'pacman_experience', 'pacman_experience_text', 'pacman_experience_quantised', 'ProlificName', 'status', 'age', 'num_approvals', 'num_rejections', 'prolific_score', 'Country of Birth', 'Current Country of Residence', 'Employment Status', 'First Language', 'Fluent languages', 'Gender identity', 'Nationality', 'Sex', 'Student Status', 'Suspicious', 'AmtPaid', 'Notes', 'Quality Rating(1-10)', 'Part1', 'Part2', 'Part3', 'MediaAI', 'HomeAI', 'AtWorkAI', 'ClassOnAI', 'DevelopAI', 'NoneAI', 'OtherAI', 'blurring_helpful_1', 'blurring_helpful_2', 'charts_helpful_1', 'charts_helpful_2', 'info_sufficient_1', 'info_sufficient_2', 'irrelevant_distracting_1', 'irrelevant_distracting_2', 'scenarios_helpful_1', 'scenarios_helpful_2', 'likertMode', 'likert1Mode', 'likert2Mode', '17.0_Z', '18.0_Z', '19.0_Z', '20.0_Z', 'blurring_helpful_1_Z', 'blurring_helpful_2_Z', 'info_sufficient_1_Z', 'info_sufficient_2_Z', 'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z', 'irrelevant_distracting_1_Z', 'irrelevant_distracting_2_Z', 'charts_helpful_1_Z', 'charts_helpful_2_Z', 'Q17_Response', 'Q17_Correct', 'Q18_Response', 'Q18_Correct', 'Q19_Response', 'Q19_Correct', 'Q20_Response', 'Q20_Correct', 'CompCorrectSum', 'CompResponseMode']\n"
     ]
    }
   ],
   "source": [
    "print(likertSlim.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1.224745\n",
      "1      0.654654\n",
      "2      0.862044\n",
      "3     -0.730096\n",
      "4     -1.336306\n",
      "         ...   \n",
      "227   -0.171499\n",
      "228   -0.636364\n",
      "229    0.000000\n",
      "230   -0.654654\n",
      "231    0.603023\n",
      "Name: likertMode_Z, Length: 232, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1.224745\n",
      "1      0.654654\n",
      "2     -1.053609\n",
      "3     -0.730096\n",
      "4     -1.336306\n",
      "         ...   \n",
      "227    0.685994\n",
      "228    0.272727\n",
      "229    0.000000\n",
      "230    1.527525\n",
      "231   -0.904534\n",
      "Name: likert1Mode_Z, Length: 232, dtype: float64\n",
      "0      1.224745\n",
      "1      0.654654\n",
      "2      0.862044\n",
      "3     -0.730096\n",
      "4     -0.534522\n",
      "         ...   \n",
      "227   -0.171499\n",
      "228   -1.545455\n",
      "229    0.000000\n",
      "230   -0.654654\n",
      "231    0.603023\n",
      "Name: likert2Mode_Z, Length: 232, dtype: float64\n",
      "0     -1.224745\n",
      "1      0.654654\n",
      "2     -0.095783\n",
      "3      0.862840\n",
      "4      1.069045\n",
      "         ...   \n",
      "227    0.685994\n",
      "228    1.181818\n",
      "229    0.000000\n",
      "230   -0.654654\n",
      "231    0.603023\n",
      "Name: CompResponseMode_Z, Length: 232, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Get mode of ZSCORES for Likert anwsers on 1, 2, and overall\n",
    "\n",
    "tmp = likertSlim.copy()\n",
    "\n",
    "tmp1 = tmp[['blurring_helpful_1_Z', \\\n",
    "      'blurring_helpful_2_Z', 'charts_helpful_1_Z', 'charts_helpful_2_Z', 'info_sufficient_1_Z', \\\n",
    "            'info_sufficient_2_Z', 'irrelevant_distracting_1_Z', 'irrelevant_distracting_2_Z', \\\n",
    "            'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z']]\n",
    "\n",
    "tmp1['likertMode_Z'] = np.where(tmp1.mode(axis=1)[2].notnull(),tmp1.mode(axis=1)[1],tmp1.mode(axis=1)[0])\n",
    "\n",
    "print(tmp1['likertMode_Z'])\n",
    "\n",
    "tmp2 = tmp1[['blurring_helpful_1_Z', 'charts_helpful_1_Z', 'info_sufficient_1_Z', 'irrelevant_distracting_1_Z', \\\n",
    "      'scenarios_helpful_1_Z']]\n",
    "\n",
    "tmp1['likert1Mode_Z'] = np.where(tmp2.mode(axis=1)[2].notnull(),tmp2.mode(axis=1)[1],tmp2.mode(axis=1)[0])\n",
    "\n",
    "print(tmp1['likert1Mode_Z'])\n",
    "\n",
    "tmp2 = tmp1[['blurring_helpful_2_Z', 'charts_helpful_2_Z', 'info_sufficient_2_Z', 'irrelevant_distracting_2_Z', \\\n",
    "      'scenarios_helpful_2_Z']]\n",
    "\n",
    "tmp1['likert2Mode_Z'] = np.where(tmp2.mode(axis=1)[2].notnull(),tmp2.mode(axis=1)[1],tmp2.mode(axis=1)[0])\n",
    "\n",
    "print(tmp1['likert2Mode_Z'])\n",
    "\n",
    "likertSlim['likertMode_Z'] = tmp1['likertMode_Z']\n",
    "likertSlim['likert1Mode_Z'] = tmp1['likert1Mode_Z']\n",
    "likertSlim['likert2Mode_Z'] = tmp1['likert2Mode_Z']\n",
    "\n",
    "tmp1['CompResponseMode_Z'] = likertSlim[['17.0_Z','18.0_Z','19.0_Z','20.0_Z']].mode(axis=1)[0]\n",
    "likertSlim['CompResponseMode_Z'] = tmp1['CompResponseMode_Z']\n",
    "print(likertSlim['CompResponseMode_Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "tmp1 = tmp[['blurring_helpful_1_Z', \\\n",
    "      'blurring_helpful_2_Z', 'charts_helpful_1_Z', 'charts_helpful_2_Z', 'info_sufficient_1_Z', \\\n",
    "            'info_sufficient_2_Z', 'irrelevant_distracting_1_Z', 'irrelevant_distracting_2_Z', \\\n",
    "            'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z','17.0_Z','18.0_Z','19.0_Z','20.0_Z']]\n",
    "tmp1['likertMode_AndComp_Z'] = np.where(tmp1.mode(axis=1)[2].notnull(),tmp1.mode(axis=1)[1],tmp1.mode(axis=1)[0])\n",
    "likertSlim['likertMode_AndComp_Z'] = tmp1['likertMode_AndComp_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brittdavis/opt/anaconda3/envs/thesis/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "tmp = likertSlim.copy()\n",
    "\n",
    "tmp1 = tmp[['blurring_helpful_1_Z', \\\n",
    "      'blurring_helpful_2_Z', 'charts_helpful_1_Z', 'charts_helpful_2_Z', 'info_sufficient_1_Z', \\\n",
    "            'info_sufficient_2_Z', 'irrelevant_distracting_1_Z', 'irrelevant_distracting_2_Z', \\\n",
    "            'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z','17.0_Z','18.0_Z','19.0_Z','20.0_Z']]\n",
    "\n",
    "tmp1['likertMode_All_Z'] = np.where(tmp1.mode(axis=1)[2].notnull(),tmp1.mode(axis=1)[1],tmp1.mode(axis=1)[0])\n",
    "likertSlim['likertMode_All_Z'] = tmp1['likertMode_All_Z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ParticipantPrivateID', 'difficulty', 'visuals', 'agents', 'QsTotal', 'QsCorrect', 'Agent_QsTotal', 'Agent_QsCorrect', 'Agent_QsWO_GhostsTotal', 'Agent_QsWO_GhostsCorrect', 'Qs1_Correct', 'Qs2_Correct', 'QsPart_Total', 'predictionsCorrect', 'predictionsTotal', 'predictions1Correct', 'predictions2Correct', 'predictionsHalfTotal', 'regionsCorrect', 'regionsTotal', 'regions1Correct', 'regions2Correct', 'regionsHalfTotal', 'levelCorrect', 'levelTotal', 'level1Correct', 'level2Correct', 'levelHalfTotal', 'ghostsCorrect', 'ghostsTotal', 'ghosts1Correct', 'ghosts2Correct', 'ghostsHalfTotal', 'comparisonsCorrect', 'comparisonsTotal', 'timeTakenMain_All', 'timeTakenMain_AgentsOnly', 'timeTaken_Consent', 'timeTaken_Demographics', 'timeTaken_AI', 'timeTaken_Agent1', 'timeTaken_Agent2', 'timeTaken_Agent3', 'time_TOTAL', 'vidPlayed', 'avgVidPlays', 'ratioVidPlaysToAvg', 'ExperimentVersion_x', 'totPerc', 'agTotPerc', 'tot1Perc', 'tot2Perc', 'Agent_QsWO_GhostsPerc', 'predPerc', 'pred1Perc', 'pred2Perc', 'regPerc', 'reg1Perc', 'reg2Perc', 'lvlPerc', 'lvl1Perc', 'lvl2Perc', 'ghostPerc', 'ghost1Perc', 'ghost2Perc', 'compPerc', 'TreeNodeKey_x', 'age_info', 'age_info_text', 'age_info_quantised', 'gender_id', 'gender_id_text', 'gender_id_quantised', 'education_level', 'education_level_text', 'education_level_quantised', 'ExperimentVersion', 'ParticipantPublicID', 'ai_involvement_1', 'ai_involvement_2', 'ai_involvement_3', 'ai_involvement_4', 'ai_involvement_5', 'ai_involvement_6', 'ai_involvement_text', 'ai_involvement_other', 'ai_opinion', 'ai_opinion_quantised', 'AI_longForm', 'pacman_experience', 'pacman_experience_text', 'pacman_experience_quantised', 'ProlificName', 'status', 'age', 'num_approvals', 'num_rejections', 'prolific_score', 'Country of Birth', 'Current Country of Residence', 'Employment Status', 'First Language', 'Fluent languages', 'Gender identity', 'Nationality', 'Sex', 'Student Status', 'Suspicious', 'AmtPaid', 'Notes', 'Quality Rating(1-10)', 'Part1', 'Part2', 'Part3', 'MediaAI', 'HomeAI', 'AtWorkAI', 'ClassOnAI', 'DevelopAI', 'NoneAI', 'OtherAI', 'blurring_helpful_1', 'blurring_helpful_2', 'charts_helpful_1', 'charts_helpful_2', 'info_sufficient_1', 'info_sufficient_2', 'irrelevant_distracting_1', 'irrelevant_distracting_2', 'scenarios_helpful_1', 'scenarios_helpful_2', 'likertMode', 'likert1Mode', 'likert2Mode', '17.0_Z', '18.0_Z', '19.0_Z', '20.0_Z', 'blurring_helpful_1_Z', 'blurring_helpful_2_Z', 'info_sufficient_1_Z', 'info_sufficient_2_Z', 'scenarios_helpful_1_Z', 'scenarios_helpful_2_Z', 'irrelevant_distracting_1_Z', 'irrelevant_distracting_2_Z', 'charts_helpful_1_Z', 'charts_helpful_2_Z', 'Q17_Response', 'Q17_Correct', 'Q18_Response', 'Q18_Correct', 'Q19_Response', 'Q19_Correct', 'Q20_Response', 'Q20_Correct', 'CompCorrectSum', 'CompResponseMode', 'likertMode_Z', 'likert1Mode_Z', 'likert2Mode_Z', 'CompResponseMode_Z', 'likertMode_AndComp_Z', 'likertMode_All_Z']\n"
     ]
    }
   ],
   "source": [
    "# print(likertSlim['compConf'].unique())\n",
    "# print(likertSlim['agTotPerc'].unique())\n",
    "print(likertSlim.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likertSlim['compPerc_Z'] = stats.zscore(likertSlim['compPerc'])\n",
    "# likertSlim['agTotPerc_Z'] = stats.zscore(likertSlim['agTotPerc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(likertSlim['compPerc_Z'])\n",
    "# print(likertSlim['agTotPerc_Z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Main Task DF to parquet:\n",
    "filePath = os.path.join(tempTopDir, 'likertSlim.parquet')\n",
    "likertSlim.to_parquet(path=filePath,compression='brotli')\n",
    "\n",
    "# table = pa.Table.from_pandas(likertSlim, safe=False)\n",
    "# Parquet with Brotli compression\n",
    "# pq.write_table(table, filePath, compression='BROTLI')\n",
    "\n",
    "# filePath = os.path.join(tempTopDir, 'GP_Main.csv')\n",
    "# mainDF.to_csv(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
